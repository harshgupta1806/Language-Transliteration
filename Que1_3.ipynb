{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009311,"end_time":"2024-04-22T12:27:39.017921","exception":false,"start_time":"2024-04-22T12:27:39.008610","status":"completed"},"tags":[]},"source":["## **Import Libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:19.245101Z","iopub.status.busy":"2024-04-29T17:22:19.244668Z","iopub.status.idle":"2024-04-29T17:22:24.023474Z","shell.execute_reply":"2024-04-29T17:22:24.022506Z","shell.execute_reply.started":"2024-04-29T17:22:19.245068Z"},"papermill":{"duration":5.240219,"end_time":"2024-04-22T12:27:44.267093","exception":false,"start_time":"2024-04-22T12:27:39.026874","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Import core libraries for deep learning and scientific computing, neural network building blocks\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F #Functional Utilities\n","import torch.optim as optim  #For Optimizer\n","\n","# Import libraries for data manipulation and analysis\n","import pandas as pd\n","import csv\n","\n","# Import libraries for progress monitoring and visualization\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","# Import libraries for logging and experimentation tracking\n","import wandb  \n","\n","# Import libraries for utility functions\n","import random  \n","import heapq  "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008822,"end_time":"2024-04-22T12:27:44.285178","exception":false,"start_time":"2024-04-22T12:27:44.276356","status":"completed"},"tags":[]},"source":["## **SET DEVICE (CPU / GPU)**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:24.025557Z","iopub.status.busy":"2024-04-29T17:22:24.025261Z","iopub.status.idle":"2024-04-29T17:22:24.057595Z","shell.execute_reply":"2024-04-29T17:22:24.056692Z","shell.execute_reply.started":"2024-04-29T17:22:24.025533Z"},"papermill":{"duration":0.067395,"end_time":"2024-04-22T12:27:44.361097","exception":false,"start_time":"2024-04-22T12:27:44.293702","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# This function determines the appropriate device (\"cpu\" or \"cuda\") to use for training.\n","def set_device():\n","    \"\"\"Sets the training device to either \"cpu\" or \"cuda\" based on availability.\n","\n","    Returns:\n","        str: The chosen device (\"cpu\" or \"cuda\").\n","    \"\"\"\n","    device = \"cpu\"  # Default device is CPU\n","\n","    # Check if a CUDA GPU is available\n","    if torch.cuda.is_available():\n","        device = \"cuda\"  # Use GPU if available for faster training\n","\n","    return device  # Return the chosen device\n","\n","# Call the function to determine the training device\n","device = set_device()\n","\n","# Print the chosen device (\"cpu\" or \"cuda\")\n","print(device)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:24.059152Z","iopub.status.busy":"2024-04-29T17:22:24.058843Z","iopub.status.idle":"2024-04-29T17:22:26.914875Z","shell.execute_reply":"2024-04-29T17:22:26.913766Z","shell.execute_reply.started":"2024-04-29T17:22:24.059126Z"},"papermill":{"duration":3.039322,"end_time":"2024-04-22T12:27:47.409602","exception":false,"start_time":"2024-04-22T12:27:44.370280","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login 57566fbb0e091de2e298a4320d872f9a2b200d12"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009457,"end_time":"2024-04-22T12:27:47.428558","exception":false,"start_time":"2024-04-22T12:27:47.419101","status":"completed"},"tags":[]},"source":["## **LOAD DATA**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:26.917814Z","iopub.status.busy":"2024-04-29T17:22:26.917506Z","iopub.status.idle":"2024-04-29T17:22:27.064789Z","shell.execute_reply":"2024-04-29T17:22:27.063657Z","shell.execute_reply.started":"2024-04-29T17:22:26.917787Z"},"papermill":{"duration":0.178081,"end_time":"2024-04-22T12:27:47.616014","exception":false,"start_time":"2024-04-22T12:27:47.437933","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_data(lang='hin'):\n","    \"\"\"\n","    Loads training, validation, and test data from CSV files.\n","\n","    Args:\n","        lang (str, optional): Language code (default: 'hin'). Defaults to 'hin'.\n","\n","    Returns:\n","        dict: A dictionary containing the loaded data and maximum sequence lengths.\n","    \"\"\"\n","\n","    # Define base paths based on language\n","    base_path = f'/kaggle/input/vocabs/Dataset/{lang}'\n","    train_path, val_path, test_path = f'{base_path}/{lang}_train.csv', f'{base_path}/{lang}_valid.csv', f'{base_path}/{lang}_test.csv'\n","\n","    # Load data using a single loop with list comprehension\n","    data_lists = []\n","    for path in [train_path, val_path, test_path]:\n","        with open(path, 'r', encoding='utf-8') as file:\n","            reader = csv.reader(file) #read csv file\n","            data_lists.append([[f\"{row[0]}$\", f\"#{row[1]}$\"] for row in reader]) \n","      \n","    data_set = []\n","    for i in range(0, 6):\n","        data_set.append([list_item[i%2] for list_item in data_lists[i//2]])\n","    \n","    train_x, train_y, val_x, val_y, test_x, test_y = data_set[0], data_set[1], data_set[2], data_set[3], data_set[4], data_set[5]\n","\n","\n","  # Convert data to NumPy arrays\n","    train_x, train_y = np.array(train_x), np.array(train_y)\n","    val_x, val_y = np.array(val_x), np.array(val_y)\n","    test_x, test_y = np.array(test_x), np.array(test_y)\n","\n","    # Find maximum sequence lengths (combined for efficiency)\n","    max_decoder_length = max(len(s) for s in np.concatenate((train_y, val_y, test_y)))\n","    max_encoder_length = max(len(s) for s in np.concatenate((train_x, val_x, test_x)))\n","\n","    # Return data as a dictionary\n","    return {\n","        \"train_x\": train_x,\n","        \"train_y\": train_y,\n","        \"val_x\": val_x,\n","        \"val_y\": val_y,\n","        \"test_x\": test_x,\n","        \"test_y\": test_y,\n","        \"max_decoder_length\": max_decoder_length,\n","        \"max_encoder_length\": max_encoder_length\n","    }\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.066329Z","iopub.status.busy":"2024-04-29T17:22:27.066027Z","iopub.status.idle":"2024-04-29T17:22:27.084655Z","shell.execute_reply":"2024-04-29T17:22:27.083769Z","shell.execute_reply.started":"2024-04-29T17:22:27.066302Z"},"papermill":{"duration":0.023639,"end_time":"2024-04-22T12:27:47.904160","exception":false,"start_time":"2024-04-22T12:27:47.880521","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def create_corpus(dictionary : dict):\n","    \"\"\"\n","    Creates vocabulary dictionaries for input and output sequences.\n","\n","    Args:\n","        dict : A dictionary containing train_y, val_y, test_y\n","    Returns:\n","        dict: A dictionary containing vocabulary information.\n","    \"\"\"\n","    train_y = dictionary[\"train_y\"]\n","    val_y = dictionary[\"val_y\"]\n","    test_y = dictionary[\"test_y\"]\n","\n","    # Define English vocabulary\n","    english_vocab = \"#$abcdefghijklmnopqrstuvwxyz\"\n","\n","    # Combine target sequences from all datasets to create a complete vocabulary\n","    all_chars = set.union((set(char for word in train_y for char in word)),\n","                            set(char for word in val_y for char in word),\n","                            set(char for word in test_y for char in word))\n","    all_chars.add('')\n","    all_chars = sorted(all_chars)\n","\n","    # Create input vocabulary dictionary (includes the empty string)\n","    input_corpus_dict = {char: idx+1 for idx, char in enumerate(english_vocab)}\n","    input_corpus_dict[''] = 0\n","    input_corpus_length = len(input_corpus_dict)\n","    \n","\n","    # Create output vocabulary dictionary (includes the empty string)\n","    output_corpus_dict = {char: idx for idx, char in enumerate(all_chars)}\n","    output_corpus_length = len(output_corpus_dict)\n","\n","    # Create dictionaries for reversed lookups (character -> index)\n","    reversed_input_corpus = {v: k for k, v in input_corpus_dict.items()}\n","    reversed_output_corpus = {v: k for k, v in output_corpus_dict.items()}\n","\n","    # Return a dictionary containing all vocabulary information\n","    return {\n","        \"input_corpus_length\": input_corpus_length,\n","        \"output_corpus_length\": output_corpus_length,\n","        \"input_corpus_dict\": input_corpus_dict,\n","        \"output_corpus_dict\": output_corpus_dict,\n","        \"reversed_input_corpus\": reversed_input_corpus,\n","        \"reversed_output_corpus\": reversed_output_corpus\n","    }\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.085984Z","iopub.status.busy":"2024-04-29T17:22:27.085721Z","iopub.status.idle":"2024-04-29T17:22:27.099235Z","shell.execute_reply":"2024-04-29T17:22:27.098468Z","shell.execute_reply.started":"2024-04-29T17:22:27.085962Z"},"papermill":{"duration":0.024579,"end_time":"2024-04-22T12:27:48.085908","exception":false,"start_time":"2024-04-22T12:27:48.061329","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def create_tensor(data_dict, corpus_dict):\n","    \"\"\"\n","    Creates PyTorch tensors for training and validation data.\n","\n","    Args:\n","        data_dict (dict) : Dictionary contaning datasets\n","        corpus_dict (dict): Dictionary containing vocabulary information.\n","\n","    Returns:\n","        dict: A dictionary containing PyTorch tensors for training and validation.\n","    \"\"\"\n","\n","    # Get maximum sequence length\n","    max_len = max(data_dict[\"max_encoder_length\"], data_dict[\"max_decoder_length\"])\n","\n","    # Function to convert sequences to tensors with padding\n","    def create_padded_tensor(sequences, vocab_dict, max_len):\n","        tensor = np.zeros((max_len, len(sequences)), dtype='int64')\n","        for i, seq in enumerate(sequences):\n","            for j, char in enumerate(seq):\n","                tensor[j, i] = vocab_dict.get(char, 0)  # Use default of 0 for missing characters\n","        return torch.tensor(tensor)\n","\n","    # Create tensors for training data\n","    train_input = create_padded_tensor(data_dict[\"train_x\"], corpus_dict[\"input_corpus_dict\"], max_len)\n","    train_output = create_padded_tensor(data_dict[\"train_y\"], corpus_dict[\"output_corpus_dict\"], max_len)\n","\n","    # Create tensors for validation data\n","    val_input = create_padded_tensor(data_dict[\"val_x\"], corpus_dict[\"input_corpus_dict\"], max_len)\n","    val_output = create_padded_tensor(data_dict[\"val_y\"], corpus_dict[\"output_corpus_dict\"], max_len)\n","\n","    # Create tensors for testing data\n","    test_input = create_padded_tensor(data_dict[\"test_x\"], corpus_dict[\"input_corpus_dict\"], max_len)\n","    test_output = create_padded_tensor(data_dict[\"test_y\"], corpus_dict[\"output_corpus_dict\"], max_len)\n","\n","    # Return dictionary containing tensors\n","    return {\n","        \"train_input\": train_input,\n","        \"train_output\": train_output,\n","        \"val_input\": val_input,\n","        \"val_output\": val_output,\n","        \"test_input\" : test_input,\n","        \"test_output\" : test_output\n","    }\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.100429Z","iopub.status.busy":"2024-04-29T17:22:27.100167Z","iopub.status.idle":"2024-04-29T17:22:27.112667Z","shell.execute_reply":"2024-04-29T17:22:27.111863Z","shell.execute_reply.started":"2024-04-29T17:22:27.100397Z"},"trusted":true},"outputs":[],"source":["def preprocess_data(lang : str):\n","    dictionary1 = load_data(lang)\n","    dictionary2 = create_corpus(dictionary1)\n","    dictionary3 = create_tensor(dictionary1, dictionary2) \n","    dictionary4 = {\n","        \"train_input\": dictionary3[\"train_input\"],\n","        \"train_output\": dictionary3[\"train_output\"],\n","        \"val_input\": dictionary3[\"val_input\"],\n","        \"val_output\": dictionary3[\"val_output\"],\n","        \"test_input\" : dictionary3[\"test_input\"],\n","        \"test_output\" : dictionary3[\"test_output\"],\n","        \"input_corpus_length\" : dictionary2[\"input_corpus_length\"],\n","        \"output_corpus_length\" : dictionary2[\"output_corpus_length\"],\n","        \"input_corpus_dict\" : dictionary2[\"input_corpus_dict\"],\n","        \"output_corpus_dict\" : dictionary2[\"output_corpus_dict\"],\n","        \"reversed_input_corpus\" : dictionary2[\"reversed_input_corpus\"],\n","        \"reversed_output_corpus\" : dictionary2[\"reversed_output_corpus\"],\n","        \"train_x\" : dictionary1[\"train_x\"],\n","        \"train_y\" : dictionary1[\"train_y\"],\n","        \"val_x\" : dictionary1[\"val_x\"],\n","        \"val_y\" : dictionary1[\"val_y\"],\n","        \"test_x\" : dictionary1[\"test_x\"],\n","        \"test_y\" : dictionary1[\"test_y\"],\n","        \"max_decoder_length\" : dictionary1[\"max_decoder_length\"],\n","        \"max_encoder_length\" : dictionary1[\"max_encoder_length\"]\n","    }   \n","\n","    return dictionary4\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## **Encoder Class**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.114101Z","iopub.status.busy":"2024-04-29T17:22:27.113765Z","iopub.status.idle":"2024-04-29T17:22:27.126893Z","shell.execute_reply":"2024-04-29T17:22:27.126136Z","shell.execute_reply.started":"2024-04-29T17:22:27.114068Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    \"\"\"\n","    Encoder class for sequence-to-sequence models.\n","    Args:\n","        PARAM (dict): Encoder hyperparameters.\n","            - input_size (int): Size of the input vocabulary.\n","            - embedding_size (int): Dimensionality of word embeddings.\n","            - hidden_size (int): Size of the hidden state in RNN cells.\n","            - num_layers (int): Number of stacked RNN layers.\n","            - drop_prob (float): Dropout probability for regularization.\n","            - cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n","            - bidirectional (bool): Whether to use a bidirectional RNN.\n","    \"\"\"\n","\n","    def __init__(self, PARAM):\n","        super(Encoder, self).__init__()\n","\n","        # Hyperparameters\n","        self.input_size = PARAM[\"encoder_input_size\"]\n","        self.embedding_size = PARAM[\"embedding_size\"]\n","        self.hidden_size = PARAM[\"hidden_size\"]\n","        self.num_layers = PARAM[\"num_layers\"]\n","        self.drop_prob = PARAM[\"drop_prob\"]\n","        self.cell_type = PARAM[\"cell_type\"]\n","        self.bidirectional = PARAM[\"bidirectional\"]\n","\n","        # Layers\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n","\n","        # Select RNN cell based on cell_type\n","        cell_map = {\n","        \"LSTM\": nn.LSTM,\n","        \"GRU\": nn.GRU,\n","        \"RNN\": nn.RNN\n","        }\n","        self.cell = cell_map[self.cell_type](\n","            self.embedding_size, self.hidden_size, self.num_layers,\n","            dropout=self.drop_prob, bidirectional=self.bidirectional\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the Encoder.\n","        Args:\n","            x : Input sequence of word indices.\n","        Returns:\n","            torch.Tensor or tuple : Hidden state (or hidden & cell states for LSTMs)\n","        \"\"\"\n","\n","        embedding = self.embedding(x) # embadding layer \n","        drops = self.dropout(embedding) # Dropout on embadding \n","        if self.cell_type == \"RNN\" or self.cell_type == \"GRU\": \n","            _, hidden = self.cell(drops) \n","            return hidden\n","        elif self.cell_type == \"LSTM\":\n","            _, (hidden, cells) = self.cell(drops)\n","            return hidden, cells\n","        else:\n","            raise ValueError(f\"Invalid RNN cell type: {self.cell_type}\") # Raise a error on invalid cell type\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Decoder** "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.128579Z","iopub.status.busy":"2024-04-29T17:22:27.128265Z","iopub.status.idle":"2024-04-29T17:22:27.142183Z","shell.execute_reply":"2024-04-29T17:22:27.141428Z","shell.execute_reply.started":"2024-04-29T17:22:27.128551Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Decoder class for sequence-to-sequence models.\n","\n","    Args:\n","        PARAM (dict): Decoder hyperparameters.\n","            - input_size (int): Size of the decoder vocabulary.\n","            - embedding_size (int): Dimensionality of word embeddings.\n","            - hidden_size (int): Size of the hidden state in RNN cells.\n","            - output_size (int): Size of the output vocabulary.\n","            - num_layers (int): Number of stacked RNN layers.\n","            - drop_prob (float): Dropout probability for regularization.\n","            - cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n","            - bidirectional (bool): Whether to use a bidirectional RNN.\n","    \"\"\"\n","\n","    def __init__(self, PARAM):\n","        super(Decoder, self).__init__()\n","\n","        # Hyperparameters\n","        self.input_size = PARAM[\"decoder_input_size\"]\n","        self.embedding_size = PARAM[\"embedding_size\"]\n","        self.hidden_size = PARAM[\"hidden_size\"]\n","        self.output_size = PARAM[\"decoder_output_size\"]\n","        self.num_layers = PARAM[\"num_layers\"]\n","        self.drop_prob = PARAM[\"drop_prob\"]\n","        self.cell_type = PARAM[\"cell_type\"]\n","        self.bidirectional = PARAM[\"bidirectional\"]\n","\n","        # Layers\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n","        self.cell_map = {\n","            \"LSTM\": nn.LSTM,\n","            \"GRU\": nn.GRU,\n","            \"RNN\": nn.RNN\n","        }\n","        self.cell = self.cell_map[self.cell_type](\n","            self.embedding_size, self.hidden_size, self.num_layers,\n","            dropout=self.drop_prob, bidirectional=self.bidirectional\n","        )\n","\n","        # Final linear layer for output prediction\n","        self.fc = nn.Linear(self.hidden_size * (2 if self.bidirectional else 1), self.output_size)\n","\n","    def forward(self, x, hidden, cell=None):\n","        \"\"\"\n","        Forward pass of the Decoder.\n","\n","        Args:\n","            x (torch.Tensor): Input sequence of word indices (single token for teacher forcing).\n","            hidden (torch.Tensor): Hidden state from the encoder.\n","            cell (torch.Tensor, optional): Cell state for LSTMs (default: None).\n","\n","        Returns:\n","            tuple(torch.Tensor): Predicted output logits, hidden state (and cell state for LSTMs).\n","        \"\"\"\n","\n","        x = x.unsqueeze(0)  # Add batch dimension for single token\n","        embedding = self.embedding(x)\n","        drops = self.dropout(embedding)\n","\n","        if self.cell_type == \"RNN\" or self.cell_type == \"GRU\":\n","            outputs, hidden = self.cell(drops, hidden)\n","        elif self.cell_type == \"LSTM\":\n","            outputs, (hidden, cell) = self.cell(drops, (hidden, cell))\n","        predictions = self.fc(outputs).squeeze(0)  # Remove batch dimension\n","\n","        if self.cell_type == \"LSTM\":\n","            predictions = F.log_softmax(predictions, dim=1)\n","            return predictions, hidden, cell\n","        return predictions, hidden\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Seq2Seq Class**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.145561Z","iopub.status.busy":"2024-04-29T17:22:27.145239Z","iopub.status.idle":"2024-04-29T17:22:27.157368Z","shell.execute_reply":"2024-04-29T17:22:27.156599Z","shell.execute_reply.started":"2024-04-29T17:22:27.145529Z"},"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    \"\"\"\n","    Seq2Seq model for sequence-to-sequence tasks.\n","\n","    Args:\n","        encoder (Encoder): Encoder module.\n","        decoder (Decoder): Decoder module.\n","        param (dict): Model hyperparameters.\n","            - tfr (float): Teacher forcing ratio for training.\n","        processed_data (dict) : containing all information of processed data\n","    \"\"\"\n","\n","    def __init__(self, encoder, decoder, param, p_data):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.teacher_forcing_ratio = param[\"tfr\"]  # Teacher forcing ratio\n","        self.processed_data = p_data\n","\n","    def forward(self, src, target):\n","        \"\"\"\n","        Forward pass of the Seq2Seq model.\n","\n","        Args:\n","            src (torch.Tensor): Source sequence of word indices.\n","            target (torch.Tensor): Target sequence of word indices.\n","\n","        Returns:\n","            torch.Tensor: Predicted output logits for each target word.\n","        \"\"\"\n","\n","        batch_size = src.shape[1]\n","        target_len = target.shape[0]\n","        target_vocab_size = self.processed_data[\"output_corpus_length\"]\n","\n","        # Initialize outputs tensor\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","\n","        # Get encoder hidden state(s)\n","        if self.encoder.cell_type == \"LSTM\":\n","            encoder_hidden, cell = self.encoder(src)\n","        elif self.encoder.cell_type == \"GRU\" or self.encoder.cell_type == \"RNN\":\n","            encoder_hidden = self.encoder(src)\n","\n","        # Start with first target word\n","        x = target[0]\n","\n","        for t in range(1, target_len):\n","            # Decode with teacher forcing or predicted output\n","            if self.encoder.cell_type == \"LSTM\":\n","                y, encoder_hidden, cell = self.decoder(x, encoder_hidden, cell) \n","            else:\n","                y, encoder_hidden = self.decoder(x, encoder_hidden, None)  \n","\n","            outputs[t] = y\n","            if random.random() < self.teacher_forcing_ratio:\n","                x = target[t]\n","            else:\n","                x = y.argmax(dim=1)\n","\n","        return outputs\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Setting Optimizer**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.158635Z","iopub.status.busy":"2024-04-29T17:22:27.158362Z","iopub.status.idle":"2024-04-29T17:22:27.171364Z","shell.execute_reply":"2024-04-29T17:22:27.170666Z","shell.execute_reply.started":"2024-04-29T17:22:27.158612Z"},"trusted":true},"outputs":[],"source":["def set_optimizer(name, model, learning_rate):\n","    \"\"\"\n","    Creates an optimizer object based on the specified name and learning rate.\n","    Args:\n","        name (str): Name of the optimizer (e.g., \"adam\", \"sgd\", \"rmsprop\", \"adagrad\").\n","        model (nn.Module): The PyTorch model to be optimized.\n","        learning_rate (float): The learning rate to use for training.\n","    Returns:\n","        torch.optim.Optimizer: The created optimizer object.\n","    \"\"\"\n","\n","    # Define the optimizer based on the provided name\n","    optimizer = None\n","    if name == \"adam\":\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    elif name == \"sgd\":\n","        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","    elif name == \"rmsprop\":\n","        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n","    elif name == \"adagrad\":\n","        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n","    else:\n","        # Raise an error if the optimizer name is invalid\n","        raise ValueError(f\"Invalid optimizer name: {name}\")\n","\n","    # Ensure an optimizer was created\n","    if optimizer is None:\n","        raise ValueError(\"Failed to create optimizer. Please check the provided name.\")\n","\n","    return optimizer\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008958,"end_time":"2024-04-22T12:27:48.957549","exception":false,"start_time":"2024-04-22T12:27:48.948591","status":"completed"},"tags":[]},"source":["## **BEAM SEARCH**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.172662Z","iopub.status.busy":"2024-04-29T17:22:27.172416Z","iopub.status.idle":"2024-04-29T17:22:27.189658Z","shell.execute_reply":"2024-04-29T17:22:27.188936Z","shell.execute_reply.started":"2024-04-29T17:22:27.172640Z"},"trusted":true},"outputs":[],"source":["def beam_search(params, model, word, device, processed_data):\n","    \"\"\"\n","    Beam search decoding for sequence-to-sequence models.\n","\n","    Args:\n","        params (dict): Model hyperparameters.\n","            - encoder_cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n","            - beam_width (int): Beam width for beam search decoding.\n","            - length_penalty (float): Penalty for longer sequences.\n","        model (nn.Module): Seq2Seq model for sequence translation.\n","        word (str): Input word to translate.\n","        device (torch.device): Device to use for computations (CPU or GPU).\n","        max_encoder_length (int): Maximum length of the encoder input sequence.\n","        input_corpus_dict (dict): Dictionary mapping input characters to integer indices.\n","        output_corpus_dict (dict): Dictionary mapping integer indices to output characters.\n","        reverse_output_corpus (dict): Dictionary mapping output characters to integer indices (for reversing prediction).\n","\n","    Returns:\n","        str: Translated sentence.\n","    \"\"\"\n","\n","    input_corpus_dict = processed_data[\"input_corpus_dict\"]\n","    output_corpus_dict = processed_data[\"output_corpus_dict\"]\n","    max_encoder_length = processed_data[\"max_encoder_length\"]\n","    reversed_output_corpus = processed_data[\"reversed_output_corpus\"]\n","    # Preprocess input sentence\n","    data = torch.zeros((max_encoder_length + 1, 1), dtype=torch.int32).to(device)\n","    for i, char in enumerate(word):\n","        data[i, 0] = input_corpus_dict[char]\n","    data[i + 1, 0] = input_corpus_dict['$']  # Add end-of-sentence marker\n","\n","    # Encode input sentence\n","    with torch.no_grad():\n","        if params[\"cell_type\"] == \"LSTM\":\n","            hidden, cell = model.encoder(data)\n","        else:\n","            hidden = model.encoder(data)\n","\n","        # Initialize beam search\n","        start_token = output_corpus_dict['#']  # Start-of-sentence symbol\n","        initial_sequence = torch.tensor([start_token]).to(device)\n","        hidden = hidden.unsqueeze(0)  # Add batch dimension\n","        beam = [(0.0, initial_sequence, hidden)]  # List of (score, sequence, hidden state) tuples\n","\n","    # Decode loop\n","        for _ in range(len(output_corpus_dict)):\n","            candidates = []  # List for storing candidate sequences\n","            for score, seq, hidden in beam:\n","                # Check for end-of-sentence token\n","                if seq[-1].item() == output_corpus_dict['$']:\n","                    candidates.append((score, seq, hidden))\n","                    continue\n","\n","                # Get last token and hidden state\n","                last_token = seq[-1].unsqueeze(0).to(device)\n","                hidden = hidden.squeeze(0)\n","\n","                # Decode step with last token\n","                if params[\"cell_type\"] == \"LSTM\":\n","                    output, hidden, cell = model.decoder(last_token, hidden, cell)\n","                else:\n","                    output, hidden = model.decoder(last_token, hidden, None)\n","\n","            # Get top-k probable tokens\n","                probabilities = F.softmax(output, dim=1)\n","                topk_probs, topk_tokens = torch.topk(probabilities, k=params[\"beam_width\"])\n","\n","                # Expand beam with top-k candidate sequences\n","                for prob, token in zip(topk_probs[0], topk_tokens[0]):\n","                    new_seq = torch.cat((seq, token.unsqueeze(0)), dim=0)\n","                    length_penalty = ((len(new_seq) - 1) / 5) ** params[\"length_penalty\"]\n","                    candidate_score = score + torch.log(prob).item() / length_penalty\n","                    candidates.append((candidate_score, new_seq, hidden.unsqueeze(0)))\n","\n","            # Select top-k beam candidates for next iteration\n","            beam = heapq.nlargest(params[\"beam_width\"], candidates, key=lambda x: x[0])\n","\n","        # Get best sequence from beam search\n","        best_score, best_sequence, _ = max(beam, key=lambda x: x[0])\n","\n","        # Convert predicted token indices to characters and reverse order\n","        translated_sentence = ''.join([reversed_output_corpus[token.item()] for token in best_sequence[1:]])[:-1]  # Remove start token and end token\n","\n","        return translated_sentence\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.190886Z","iopub.status.busy":"2024-04-29T17:22:27.190618Z","iopub.status.idle":"2024-04-29T17:22:27.203832Z","shell.execute_reply":"2024-04-29T17:22:27.203118Z","shell.execute_reply.started":"2024-04-29T17:22:27.190865Z"},"trusted":true},"outputs":[],"source":["def run_epoch(model, data_loader, optimizer, criterion, processed_data):\n","    \"\"\"\n","    Train the Seq2Seq model for one epoch.\n","\n","    Args:\n","        model (nn.Module): Seq2Seq model to train.\n","        data_loader (List): List containing training_data.\n","        optimizer (Optimizer): Optimizer for updating model parameters.\n","        criterion (nn.Module): Loss function for calculating training loss.\n","\n","    Returns:\n","        tuple(float, float): Training accuracy and average loss.\n","    \"\"\"\n","\n","    model.train()  # Set model to training mode\n","    total_loss, total_words, correct_predictions = 0, 0, 0\n","\n","    with tqdm(total=len(data_loader[0]), desc='Training') as pbar:  # Gradient accumulation\n","        for _ , (source, target) in enumerate(zip(data_loader[0], data_loader[1])):\n","            source, target = source.to(device), target.to(device)  # Move data to device\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            output = model(source, target)\n","            target = target.reshape(-1)  # Reshape target for loss calculation\n","            output = output.reshape(-1, output.shape[2])  # Reshape output\n","            \n","            #Ignore the padding\n","            pad_mask = (target != processed_data['output_corpus_dict'][''])\n","            target = target[pad_mask]\n","            output = output[pad_mask]\n","\n","            # Calculate loss\n","            loss = criterion(output, target)\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","            optimizer.step()  # Update model parameters\n","\n","            # Calculate total loss, total words, correct_predictions\n","            total_loss += loss.item()\n","            total_words += target.size(0)\n","            correct_predictions += torch.sum(torch.argmax(output, dim = 1) == target).item()\n","            pbar.update(1)\n","\n","    # Calculate Accuracy and Avg Loss\n","    accuracy = correct_predictions / total_words\n","    avg_loss = total_loss / len(data_loader[0])\n","\n","    return accuracy, avg_loss\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.205572Z","iopub.status.busy":"2024-04-29T17:22:27.204980Z","iopub.status.idle":"2024-04-29T17:22:27.217024Z","shell.execute_reply":"2024-04-29T17:22:27.216099Z","shell.execute_reply.started":"2024-04-29T17:22:27.205543Z"},"trusted":true},"outputs":[],"source":["def evaluate_character_level(model, val_data_loader, loss_fn, processed_data):\n","    \"\"\"\n","    Evaluate the Seq2Seq model on character-level data.\n","\n","    Args:\n","        model (nn.Module): Seq2Seq model to evaluate.\n","        val_data_loader (DataLoader): Data loader for validation data.\n","        loss_fn (nn.Module): Loss function for calculating validation loss.\n","\n","    Returns:\n","        tuple(float, float): Validation accuracy and average loss.\n","    \"\"\"\n","\n","    model.eval()  # Set model to evaluation mode\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_words = 0\n","        correct_predictions = 0\n","\n","        with tqdm(total=len(val_data_loader[0]), desc='Validation') as pbar:\n","            for src, tar in zip(val_data_loader[0], val_data_loader[1]):\n","                target, source = tar.to(device), src.to(device)\n","\n","                # Apply model\n","                output = model(source, target)\n","\n","                # Reshape target and output\n","                target = target.reshape(-1)\n","                output = output.reshape(-1, output.shape[2])\n","                \n","                # Ignore the padding \n","                pad_mask = (target != processed_data['output_corpus_dict'][''])\n","                target = target[pad_mask]\n","                output = output[pad_mask]\n","\n","                #Calculate total_loss, total_words, correct_predictions\n","                val_loss = loss_fn(output, target)\n","                total_loss += val_loss.item()\n","                total_words += target.size(0)\n","                correct_predictions += torch.sum(torch.argmax(output, dim=1) == target).item()\n","                pbar.update(1)\n","        \n","    accuracy = correct_predictions / total_words\n","    avg_loss = total_loss / len(val_data_loader[0])\n","\n","    return accuracy, avg_loss\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.218394Z","iopub.status.busy":"2024-04-29T17:22:27.218129Z","iopub.status.idle":"2024-04-29T17:22:27.231391Z","shell.execute_reply":"2024-04-29T17:22:27.230644Z","shell.execute_reply.started":"2024-04-29T17:22:27.218372Z"},"trusted":true},"outputs":[],"source":["def evaluate_model_beam_search(params, model, device, processed_data):\n","    \"\"\"\n","    Evaluates the model using beam search and returns accuracy and correct predictions.\n","\n","    Args:\n","        model (torch.nn.Module): The machine translation model to evaluate.\n","        val_data (torch.Tensor): The validation data tensor.\n","        vx (list): List of source words for beam search.\n","        vy (list): List of target words for beam search.\n","        device (str): Device to use for computation (e.g., 'cpu' or 'cuda').\n","        processed_data (dict): Preprocessed data dictionary.\n","\n","    Returns:\n","        tuple: A tuple containing validation accuracy (float) and correct predictions (int).\n","    \"\"\"\n","\n","# Set the model to evaluation mode\n","    model.eval()\n","\n","    # Disable gradient computation during inference\n","    with torch.no_grad():\n","        # Initialize counters\n","        total_words = 0\n","        correct_predictions = 0\n","        \n","        # Iterate through the validation data with tqdm progress bar\n","        with tqdm(total=len(processed_data[\"val_x\"]), desc='Beam_Search') as pbar:\n","            for word, target_word in zip(processed_data[\"val_x\"], processed_data[\"val_y\"]):\n","                # Increment the total words counter\n","                total_words += 1\n","                \n","                # Perform beam search to predict the next word\n","                predicted_word = beam_search(params, model, word, device, processed_data)\n","#                 print(target_word, predicted_word)\n","                # Check if the predicted word matches the target word\n","                if predicted_word == target_word[1:-1]:  # Remove start and end tokens\n","                    correct_predictions += 1\n","                \n","                # Update the progress bar\n","                pbar.update(1)\n","\n","    # Calculate accuracy\n","    accuracy = correct_predictions / total_words\n","\n","    # Return accuracy and number of correct predictions\n","    return accuracy, correct_predictions\n","\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009195,"end_time":"2024-04-22T12:27:49.012983","exception":false,"start_time":"2024-04-22T12:27:49.003788","status":"completed"},"tags":[]},"source":["## **Train Using Beam Search**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.233073Z","iopub.status.busy":"2024-04-29T17:22:27.232684Z","iopub.status.idle":"2024-04-29T17:22:27.246662Z","shell.execute_reply":"2024-04-29T17:22:27.245861Z","shell.execute_reply.started":"2024-04-29T17:22:27.233049Z"},"papermill":{"duration":0.009035,"end_time":"2024-04-22T12:27:49.031338","exception":false,"start_time":"2024-04-22T12:27:49.022303","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def training(PARAM, processed_data, device, wandb_log = 0):\n","    # initilize wandb with project\n","    if wandb_log == 1:\n","        wandb.init(project='DL-Assignment3')\n","        wandb.run.name = 'Training'\n","    \n","    # Set Learning Rate, epochsm batch_size\n","    learning_rate = PARAM[\"learning_rate\"]\n","    epochs = PARAM[\"epochs\"]\n","    batch_size = PARAM[\"batch_size\"]\n","\n","    # Copy encoder and decoder to device\n","    encoder = Encoder(PARAM).to(device)\n","    decoder = Decoder(PARAM).to(device)\n","\n","#     # Initialize model\n","    model = Seq2Seq(encoder, decoder, PARAM, processed_data).to(device)\n","    print(model)\n","\n","    # Define loss function and optimizer\n","    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","    optimizer = set_optimizer(PARAM[\"optimizer\"], model, learning_rate)\n","\n","    # Split dataset into batches\n","    train_batches_x = torch.split(processed_data[\"train_input\"], batch_size, dim=1)\n","    train_batches_y = torch.split(processed_data[\"train_output\"], batch_size, dim=1)\n","    val_batches_x = torch.split(processed_data[\"val_input\"], batch_size, dim=1)\n","    val_batches_y = torch.split(processed_data[\"val_output\"], batch_size, dim=1)\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        print(f\"Epoch :: {epoch+1}/{epochs}\")\n","        \n","        # Train the model on training data\n","        data_loader = [train_batches_x, train_batches_y]\n","        accuracy, avg_loss = run_epoch(model, data_loader, optimizer, loss_function, processed_data)  # Average loss per batch\n","\n","        # Evaluate model character wise\n","        val_data_loader = [val_batches_x, val_batches_y]\n","        val_accuracy, val_avg_loss = evaluate_character_level(model, val_data_loader, loss_function, processed_data)\n","        \n","        # Evaluate model word wise\n","        val_accuracy_beam, val_correct_pred_beam = evaluate_model_beam_search(PARAM, model, device, processed_data)\n","        total_words = processed_data[\"val_input\"].shape[1] \n","\n","        # print epochs\n","        print(f\"Epoch : {epoch+1} Train Accuracy: {accuracy*100:.4f}, Train Loss: {avg_loss:.4f}\\nValidation Accuracy: {val_accuracy*100:.4f}, Validation Loss: {val_avg_loss:.4f}, \\nValidation Acc. With BeamSearch: {val_accuracy_beam*100:.4f}, Correctly Predicted : {val_correct_pred_beam}/{total_words}\")\n","\n","        # Log on wandb\n","        if wandb_log:\n","            wandb.log(\n","                    {\n","                        'epoch': epoch+1,\n","                        'training_loss' : avg_loss,\n","                        'training_accuracy' : accuracy,\n","                        'validation_loss' : val_avg_loss,\n","                        'validation_accuracy_using_char' : val_accuracy,\n","                        'validation_accuracy_using_word' : val_accuracy_beam,\n","                        'correctly_predicted' : val_correct_pred_beam\n","                    }\n","                )\n","    return model, val_accuracy_beam"]},{"cell_type":"markdown","metadata":{},"source":["## **Get Data**"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:27.248498Z","iopub.status.busy":"2024-04-29T17:22:27.247940Z","iopub.status.idle":"2024-04-29T17:22:28.235408Z","shell.execute_reply":"2024-04-29T17:22:28.234612Z","shell.execute_reply.started":"2024-04-29T17:22:27.248467Z"},"trusted":true},"outputs":[],"source":["processed_data = preprocess_data('hin')"]},{"cell_type":"markdown","metadata":{},"source":["## **HYPER PARAMETERS**"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:28.237156Z","iopub.status.busy":"2024-04-29T17:22:28.236739Z","iopub.status.idle":"2024-04-29T17:22:28.243876Z","shell.execute_reply":"2024-04-29T17:22:28.242736Z","shell.execute_reply.started":"2024-04-29T17:22:28.237121Z"},"trusted":true},"outputs":[],"source":["HYPER_PARAM = {\n","    \"encoder_input_size\": processed_data[\"input_corpus_length\"],\n","    \"embedding_size\": 256,\n","    \"hidden_size\": 512,\n","    \"num_layers\": 2,\n","    \"drop_prob\": 0.3,\n","    \"cell_type\": \"GRU\",\n","    \"decoder_input_size\": processed_data[\"output_corpus_length\"],\n","    \"decoder_output_size\": processed_data[\"output_corpus_length\"],\n","    \"beam_width\" : 4,\n","    \"length_penalty\" : 0.6,\n","    \"bidirectional\" : True,\n","    \"learning_rate\" : 0.01,\n","    \"batch_size\" : 128,\n","    \"epochs\" : 5,\n","    \"optimizer\" : \"adagrad\",\n","    \"tfr\" : 0.7,\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## **Training Model on Hyper Parameters**"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:22:28.245571Z","iopub.status.busy":"2024-04-29T17:22:28.245053Z","iopub.status.idle":"2024-04-29T17:35:11.308566Z","shell.execute_reply":"2024-04-29T17:35:11.307580Z","shell.execute_reply.started":"2024-04-29T17:22:28.245539Z"},"papermill":{"duration":0.017322,"end_time":"2024-04-22T12:27:49.170183","exception":false,"start_time":"2024-04-22T12:27:49.152861","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (embedding): Embedding(29, 256)\n","    (cell): GRU(256, 512, num_layers=2, dropout=0.3, bidirectional=True)\n","  )\n","  (decoder): Decoder(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (embedding): Embedding(68, 256)\n","    (cell): GRU(256, 512, num_layers=2, dropout=0.3, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=68, bias=True)\n","  )\n",")\n","Epoch :: 1/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 400/400 [00:35<00:00, 11.23it/s]\n","Validation: 100%|██████████| 32/32 [00:00<00:00, 34.39it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [01:55<00:00, 35.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1 Train Accuracy: 51.9078, Train Loss: 1.7638\n","Validation Accuracy: 67.8863, Validation Loss: 1.1704, \n","Validation Acc. With BeamSearch: 28.7109, Correctly Predicted : 1176/4096\n","Epoch :: 2/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 400/400 [00:34<00:00, 11.54it/s]\n","Validation: 100%|██████████| 32/32 [00:00<00:00, 34.93it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [01:56<00:00, 35.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 2 Train Accuracy: 70.4693, Train Loss: 1.0662\n","Validation Accuracy: 72.4764, Validation Loss: 1.0280, \n","Validation Acc. With BeamSearch: 36.8408, Correctly Predicted : 1509/4096\n","Epoch :: 3/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 400/400 [00:34<00:00, 11.56it/s]\n","Validation: 100%|██████████| 32/32 [00:00<00:00, 34.86it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [01:56<00:00, 35.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 3 Train Accuracy: 74.6496, Train Loss: 0.9329\n","Validation Accuracy: 73.3590, Validation Loss: 1.0065, \n","Validation Acc. With BeamSearch: 38.8428, Correctly Predicted : 1591/4096\n","Epoch :: 4/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 400/400 [00:34<00:00, 11.57it/s]\n","Validation: 100%|██████████| 32/32 [00:00<00:00, 34.72it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [01:56<00:00, 35.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 4 Train Accuracy: 77.1523, Train Loss: 0.8560\n","Validation Accuracy: 74.3388, Validation Loss: 0.9731, \n","Validation Acc. With BeamSearch: 40.1855, Correctly Predicted : 1646/4096\n","Epoch :: 5/5\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 400/400 [00:34<00:00, 11.57it/s]\n","Validation: 100%|██████████| 32/32 [00:00<00:00, 34.62it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [01:56<00:00, 35.10it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch : 5 Train Accuracy: 78.8832, Train Loss: 0.8016\n","Validation Accuracy: 74.8243, Validation Loss: 0.9626, \n","Validation Acc. With BeamSearch: 41.4307, Correctly Predicted : 1697/4096\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model, acc = training(HYPER_PARAM, processed_data, device, wandb_log = 0)"]},{"cell_type":"markdown","metadata":{},"source":["## **Transliteration on Random Data**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:35:58.140524Z","iopub.status.busy":"2024-04-29T17:35:58.139672Z","iopub.status.idle":"2024-04-29T17:35:58.439559Z","shell.execute_reply":"2024-04-29T17:35:58.438529Z","shell.execute_reply.started":"2024-04-29T17:35:58.140489Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","परित्रणाय साधुनाम विनाशाया चदुष्कृताम धर्मा सम्थस्पन्थर्या संभवामी युगे युगे "]}],"source":["sentance = \"paritraanaaya sadhuunaam vinaashaaya chadushkritaam dharma samsthaapanaarthaaya sambhavaami yuge yuge\"\n","\n","sentance = sentance.lower()\n","lst = sentance.split(\" \")\n","print(type(lst))\n","for word in lst:\n","    output_sequence = beam_search(HYPER_PARAM, model, word ,device, processed_data)\n","    print(output_sequence, end = \" \")"]},{"cell_type":"markdown","metadata":{},"source":["## **Sweep Config**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:35:11.603217Z","iopub.status.busy":"2024-04-29T17:35:11.602666Z","iopub.status.idle":"2024-04-29T17:35:11.610688Z","shell.execute_reply":"2024-04-29T17:35:11.609743Z","shell.execute_reply.started":"2024-04-29T17:35:11.603190Z"},"papermill":{"duration":0.020451,"end_time":"2024-04-22T12:27:49.200094","exception":false,"start_time":"2024-04-22T12:27:49.179643","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sweep_config = {\n","            'name': 'sweep-bayes-1',\n","            'method': 'bayes',\n","            'metric': { 'goal': 'maximize','name': 'Accuracy'},\n","            'parameters': \n","                {\n","                    'epochs': {'values': [10]},\n","                    'cell_type': {'values': ['RNN', 'LSTM', 'GRU']},\n","                    'embedding_size': {'values': [128, 256, 512]},\n","                    'hidden_size': {'values': [128, 256, 512, 1024]},\n","                    'num_layers': {'values': [1, 2, 3]},\n","                    'dropout': {'values': [0.3, 0.5, 0.7]},\n","                    'optimizer' : {'values' : ['adam', 'sgd', 'rmsprop', 'adagrad']},\n","                    'learning_rate': {'values': [0.001, 0.005, 0.01, 0.1]},\n","                    'batch_size': {'values': [32, 64]},\n","                    'teacher_fr' : {'values': [0.3, 0.5, 0.7]},\n","                    'length_penalty' : {'values': [0.4, 0.5, 0.6]},\n","                    'bi_dir' : {'values': [True, False]},\n","                    'beam_width': {'values': [1, 2, 3]}\n","                }\n","            }"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:35:11.612115Z","iopub.status.busy":"2024-04-29T17:35:11.611855Z","iopub.status.idle":"2024-04-29T17:35:11.629338Z","shell.execute_reply":"2024-04-29T17:35:11.628403Z","shell.execute_reply.started":"2024-04-29T17:35:11.612094Z"},"papermill":{"duration":0.021012,"end_time":"2024-04-22T12:27:49.230944","exception":false,"start_time":"2024-04-22T12:27:49.209932","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def train():\n","    var1 = wandb.init(project=\"DL-Assignment3\")\n","    var2 = var1.config\n","   \n","    wandb.run.name = (f\"cell_type:{var2.cell_type}_epochs:{var2.epochs}_lr:{var2.learning_rate}_batch_size:{var2.batch_size}_beam_width:{var2.beam_width}_opt:{var2.optimizer}_dropout:{var2.dropout}_teacher_fr:{var2.teacher_fr}_embadding_size:{var2.embedding_size}\")\n","    \n","    HYPER_PARAM = {\n","    \"encoder_input_size\": processed_data[\"input_corpus_length\"],\n","    \"embedding_size\": var2.embedding_size,\n","    \"hidden_size\": var2.hidden_size,\n","    \"num_layers\": var2.num_layers,\n","    \"drop_prob\": var2.dropout,\n","    \"cell_type\": var2.cell_type,\n","    \"decoder_input_size\": processed_data[\"output_corpus_length\"],\n","    \"decoder_output_size\": processed_data[\"output_corpus_length\"],\n","    \"beam_width\" : var2.beam_width,\n","    \"length_penalty\" : var2.length_penalty,\n","    \"bidirectional\" : var2.bi_dir,\n","    \"learning_rate\" : var2.learning_rate,\n","    \"batch_size\" : var2.batch_size,\n","    \"epochs\" : var2.epochs,\n","    \"optimizer\" : var2.optimizer,\n","    \"tfr\" : var2.teacher_fr,\n","}\n","\n","    model, accuracy = training(HYPER_PARAM, wandb_log = 1)\n","    wandb.log({\n","                \"Accuracy\" : accuracy\n","            })"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-04-29T17:35:11.630529Z","iopub.status.busy":"2024-04-29T17:35:11.630284Z","iopub.status.idle":"2024-04-29T17:35:11.643354Z","shell.execute_reply":"2024-04-29T17:35:11.642579Z","shell.execute_reply.started":"2024-04-29T17:35:11.630498Z"},"papermill":{"duration":10628.113884,"end_time":"2024-04-22T15:24:57.354431","exception":false,"start_time":"2024-04-22T12:27:49.240547","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sweep_id = wandb.sweep(sweep_config, project=\"DL-Assignment3\")\n","wandb.agent(sweep_id, train, count = 2)\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":7.61018,"end_time":"2024-04-22T15:25:12.330452","exception":false,"start_time":"2024-04-22T15:25:04.720272","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4830707,"sourceId":8164175,"sourceType":"datasetVersion"},{"datasetId":4844106,"sourceId":8181791,"sourceType":"datasetVersion"},{"datasetId":4861591,"sourceId":8205199,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"papermill":{"default_parameters":{},"duration":10667.002796,"end_time":"2024-04-22T15:25:23.121216","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-22T12:27:36.118420","version":"2.5.0"}},"nbformat":4,"nbformat_minor":4}
