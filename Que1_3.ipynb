{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009311,"end_time":"2024-04-22T12:27:39.017921","exception":false,"start_time":"2024-04-22T12:27:39.008610","status":"completed"},"tags":[]},"source":["## **Import Libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:46:45.504534Z","iopub.status.busy":"2024-05-11T18:46:45.503820Z","iopub.status.idle":"2024-05-11T18:46:51.066678Z","shell.execute_reply":"2024-05-11T18:46:51.065605Z","shell.execute_reply.started":"2024-05-11T18:46:45.504500Z"},"papermill":{"duration":5.240219,"end_time":"2024-04-22T12:27:44.267093","exception":false,"start_time":"2024-04-22T12:27:39.026874","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Import core libraries for deep learning and scientific computing, neural network building blocks\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F #Functional Utilities\n","import torch.optim as optim  #For Optimizer\n","\n","# Import libraries for data manipulation and analysis\n","import pandas as pd\n","import csv\n","\n","# Import libraries for progress monitoring and visualization\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","\n","# Import libraries for logging and experimentation tracking\n","import wandb  \n","\n","# Import libraries for utility functions\n","import random  \n","import heapq  "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008822,"end_time":"2024-04-22T12:27:44.285178","exception":false,"start_time":"2024-04-22T12:27:44.276356","status":"completed"},"tags":[]},"source":["## **SET DEVICE (CPU / GPU)**"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:46:51.069185Z","iopub.status.busy":"2024-05-11T18:46:51.068808Z","iopub.status.idle":"2024-05-11T18:46:51.107151Z","shell.execute_reply":"2024-05-11T18:46:51.105991Z","shell.execute_reply.started":"2024-05-11T18:46:51.069148Z"},"papermill":{"duration":0.067395,"end_time":"2024-04-22T12:27:44.361097","exception":false,"start_time":"2024-04-22T12:27:44.293702","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# This function determines the appropriate device (\"cpu\" or \"cuda\") to use for training.\n","def set_device():\n","    \"\"\"Sets the training device to either \"cpu\" or \"cuda\" based on availability.\n","\n","    Returns:\n","        str: The chosen device (\"cpu\" or \"cuda\").\n","    \"\"\"\n","    device = \"cpu\"  # Default device is CPU\n","\n","    # Check if a CUDA GPU is available\n","    if torch.cuda.is_available():\n","        device = \"cuda\"  # Use GPU if available for faster training\n","\n","    return device  # Return the chosen device\n","\n","# Call the function to determine the training device\n","device = set_device()\n","\n","# Print the chosen device (\"cpu\" or \"cuda\")\n","print(device)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T20:55:50.824910Z","iopub.status.busy":"2024-05-07T20:55:50.824300Z","iopub.status.idle":"2024-05-07T20:55:53.727075Z","shell.execute_reply":"2024-05-07T20:55:53.725986Z","shell.execute_reply.started":"2024-05-07T20:55:50.824878Z"},"papermill":{"duration":3.039322,"end_time":"2024-04-22T12:27:47.409602","exception":false,"start_time":"2024-04-22T12:27:44.370280","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login 57566fbb0e091de2e298a4320d872f9a2b200d12"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009457,"end_time":"2024-04-22T12:27:47.428558","exception":false,"start_time":"2024-04-22T12:27:47.419101","status":"completed"},"tags":[]},"source":["## **LOAD DATA**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:46:52.879386Z","iopub.status.busy":"2024-05-11T18:46:52.879019Z","iopub.status.idle":"2024-05-11T18:46:52.893705Z","shell.execute_reply":"2024-05-11T18:46:52.892628Z","shell.execute_reply.started":"2024-05-11T18:46:52.879356Z"},"papermill":{"duration":0.178081,"end_time":"2024-04-22T12:27:47.616014","exception":false,"start_time":"2024-04-22T12:27:47.437933","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_data(lang='hin'):\n","    \"\"\"\n","    Loads training, validation, and test data from CSV files.\n","\n","    Args:\n","        lang (str, optional): Language code (default: 'hin'). Defaults to 'hin'.\n","\n","    Returns:\n","        dict: A dictionary containing the loaded data and maximum sequence lengths.\n","    \"\"\"\n","\n","    # Define base paths based on language\n","    base_path = f'/kaggle/input/vocabs/Dataset/{lang}'\n","    train_path, val_path, test_path = f'{base_path}/{lang}_train.csv', f'{base_path}/{lang}_valid.csv', f'{base_path}/{lang}_test.csv'\n","\n","    # Load data using a single loop with list comprehension\n","    data_lists = []\n","    for path in [train_path, val_path, test_path]:\n","        with open(path, 'r', encoding='utf-8') as file:\n","            reader = csv.reader(file) #read csv file\n","            data_lists.append([[f\"{row[0]}$\", f\"#{row[1]}$\"] for row in reader]) \n","      \n","    data_set = []\n","    for i in range(0, 6):\n","        data_set.append([list_item[i%2] for list_item in data_lists[i//2]])\n","    \n","    train_x, train_y, val_x, val_y, test_x, test_y = data_set[0], data_set[1], data_set[2], data_set[3], data_set[4], data_set[5]\n","\n","\n","  # Convert data to NumPy arrays\n","    train_x, train_y = np.array(train_x), np.array(train_y)\n","    val_x, val_y = np.array(val_x), np.array(val_y)\n","    test_x, test_y = np.array(test_x), np.array(test_y)\n","\n","    # Find maximum sequence lengths (combined for efficiency)\n","    max_decoder_length = max(len(s) for s in np.concatenate((train_y, val_y, test_y)))\n","    max_encoder_length = max(len(s) for s in np.concatenate((train_x, val_x, test_x)))\n","\n","    # Return data as a dictionary\n","    return {\n","        \"train_x\": train_x,\n","        \"train_y\": train_y,\n","        \"val_x\": val_x,\n","        \"val_y\": val_y,\n","        \"test_x\": test_x,\n","        \"test_y\": test_y,\n","        \"max_decoder_length\": max_decoder_length,\n","        \"max_encoder_length\": max_encoder_length\n","    }\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:46:57.991468Z","iopub.status.busy":"2024-05-11T18:46:57.991077Z","iopub.status.idle":"2024-05-11T18:46:58.003047Z","shell.execute_reply":"2024-05-11T18:46:58.001569Z","shell.execute_reply.started":"2024-05-11T18:46:57.991437Z"},"papermill":{"duration":0.023639,"end_time":"2024-04-22T12:27:47.904160","exception":false,"start_time":"2024-04-22T12:27:47.880521","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def create_corpus(dictionary : dict):\n","    \"\"\"\n","    Creates vocabulary dictionaries for input and output sequences.\n","\n","    Args:\n","        dict : A dictionary containing train_y, val_y, test_y\n","    Returns:\n","        dict: A dictionary containing vocabulary information.\n","    \"\"\"\n","    train_y = dictionary[\"train_y\"]\n","    val_y = dictionary[\"val_y\"]\n","    test_y = dictionary[\"test_y\"]\n","\n","    # Define English vocabulary\n","    english_vocab = \"#$abcdefghijklmnopqrstuvwxyz\"\n","\n","    # Combine target sequences from all datasets to create a complete vocabulary\n","    all_chars = set.union((set(char for word in train_y for char in word)),\n","                            set(char for word in val_y for char in word),\n","                            set(char for word in test_y for char in word))\n","    all_chars.add('')\n","    all_chars = sorted(all_chars)\n","\n","    # Create input vocabulary dictionary (includes the empty string)\n","    input_corpus_dict = {char: idx+1 for idx, char in enumerate(english_vocab)}\n","    input_corpus_dict[''] = 0\n","    input_corpus_length = len(input_corpus_dict)\n","    \n","\n","    # Create output vocabulary dictionary (includes the empty string)\n","    output_corpus_dict = {char: idx for idx, char in enumerate(all_chars)}\n","    output_corpus_length = len(output_corpus_dict)\n","\n","    # Create dictionaries for reversed lookups (character -> index)\n","    reversed_input_corpus = {v: k for k, v in input_corpus_dict.items()}\n","    reversed_output_corpus = {v: k for k, v in output_corpus_dict.items()}\n","\n","    # Return a dictionary containing all vocabulary information\n","    return {\n","        \"input_corpus_length\": input_corpus_length,\n","        \"output_corpus_length\": output_corpus_length,\n","        \"input_corpus_dict\": input_corpus_dict,\n","        \"output_corpus_dict\": output_corpus_dict,\n","        \"reversed_input_corpus\": reversed_input_corpus,\n","        \"reversed_output_corpus\": reversed_output_corpus\n","    }\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:46:59.784050Z","iopub.status.busy":"2024-05-11T18:46:59.783111Z","iopub.status.idle":"2024-05-11T18:46:59.794630Z","shell.execute_reply":"2024-05-11T18:46:59.793458Z","shell.execute_reply.started":"2024-05-11T18:46:59.784013Z"},"papermill":{"duration":0.024579,"end_time":"2024-04-22T12:27:48.085908","exception":false,"start_time":"2024-04-22T12:27:48.061329","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def create_tensor(data_dict, corpus_dict):\n","    \"\"\"\n","    Creates PyTorch tensors for training and validation data.\n","\n","    Args:\n","        data_dict (dict) : Dictionary contaning datasets\n","        corpus_dict (dict): Dictionary containing vocabulary information.\n","\n","    Returns:\n","        dict: A dictionary containing PyTorch tensors for training and validation.\n","    \"\"\"\n","\n","    # Get maximum sequence length\n","    max_len = max(data_dict[\"max_encoder_length\"], data_dict[\"max_decoder_length\"])\n","\n","    # Function to convert sequences to tensors with padding\n","    def create_padded_tensor(sequences, vocab_dict, max_len):\n","        tensor = np.zeros((max_len, len(sequences)), dtype='int64')\n","        for i, seq in enumerate(sequences):\n","            for j, char in enumerate(seq):\n","                tensor[j, i] = vocab_dict.get(char, 0)  # Use default of 0 for missing characters\n","        return torch.tensor(tensor)\n","\n","    # Create tensors for training data\n","    train_input = create_padded_tensor(data_dict[\"train_x\"], corpus_dict[\"input_corpus_dict\"], max_len)\n","    train_output = create_padded_tensor(data_dict[\"train_y\"], corpus_dict[\"output_corpus_dict\"], max_len)\n","\n","    # Create tensors for validation data\n","    val_input = create_padded_tensor(data_dict[\"val_x\"], corpus_dict[\"input_corpus_dict\"], max_len)\n","    val_output = create_padded_tensor(data_dict[\"val_y\"], corpus_dict[\"output_corpus_dict\"], max_len)\n","\n","    # Create tensors for testing data\n","    test_input = create_padded_tensor(data_dict[\"test_x\"], corpus_dict[\"input_corpus_dict\"], max_len)\n","    test_output = create_padded_tensor(data_dict[\"test_y\"], corpus_dict[\"output_corpus_dict\"], max_len)\n","\n","    # Return dictionary containing tensors\n","    return {\n","        \"train_input\": train_input,\n","        \"train_output\": train_output,\n","        \"val_input\": val_input,\n","        \"val_output\": val_output,\n","        \"test_input\" : test_input,\n","        \"test_output\" : test_output\n","    }\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:01.510155Z","iopub.status.busy":"2024-05-11T18:47:01.509782Z","iopub.status.idle":"2024-05-11T18:47:01.519744Z","shell.execute_reply":"2024-05-11T18:47:01.518304Z","shell.execute_reply.started":"2024-05-11T18:47:01.510127Z"},"trusted":true},"outputs":[],"source":["def preprocess_data(lang : str):\n","    dictionary1 = load_data(lang)\n","    dictionary2 = create_corpus(dictionary1)\n","    dictionary3 = create_tensor(dictionary1, dictionary2) \n","    dictionary4 = {\n","        \"train_input\": dictionary3[\"train_input\"],\n","        \"train_output\": dictionary3[\"train_output\"],\n","        \"val_input\": dictionary3[\"val_input\"],\n","        \"val_output\": dictionary3[\"val_output\"],\n","        \"test_input\" : dictionary3[\"test_input\"],\n","        \"test_output\" : dictionary3[\"test_output\"],\n","        \"input_corpus_length\" : dictionary2[\"input_corpus_length\"],\n","        \"output_corpus_length\" : dictionary2[\"output_corpus_length\"],\n","        \"input_corpus_dict\" : dictionary2[\"input_corpus_dict\"],\n","        \"output_corpus_dict\" : dictionary2[\"output_corpus_dict\"],\n","        \"reversed_input_corpus\" : dictionary2[\"reversed_input_corpus\"],\n","        \"reversed_output_corpus\" : dictionary2[\"reversed_output_corpus\"],\n","        \"train_x\" : dictionary1[\"train_x\"],\n","        \"train_y\" : dictionary1[\"train_y\"],\n","        \"val_x\" : dictionary1[\"val_x\"],\n","        \"val_y\" : dictionary1[\"val_y\"],\n","        \"test_x\" : dictionary1[\"test_x\"],\n","        \"test_y\" : dictionary1[\"test_y\"],\n","        \"max_decoder_length\" : dictionary1[\"max_decoder_length\"],\n","        \"max_encoder_length\" : dictionary1[\"max_encoder_length\"]\n","    }   \n","\n","    return dictionary4\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Encoder Class**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:02.011969Z","iopub.status.busy":"2024-05-11T18:47:02.011561Z","iopub.status.idle":"2024-05-11T18:47:02.027093Z","shell.execute_reply":"2024-05-11T18:47:02.025922Z","shell.execute_reply.started":"2024-05-11T18:47:02.011935Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    \"\"\"\n","    Encoder class for sequence-to-sequence models.\n","    Args:\n","        PARAM (dict): Encoder hyperparameters.\n","            - input_size (int): Size of the input vocabulary.\n","            - embedding_size (int): Dimensionality of word embeddings.\n","            - hidden_size (int): Size of the hidden state in RNN cells.\n","            - num_layers (int): Number of stacked RNN layers.\n","            - drop_prob (float): Dropout probability for regularization.\n","            - cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n","            - bidirectional (bool): Whether to use a bidirectional RNN.\n","    \"\"\"\n","\n","    def __init__(self, PARAM):\n","        super(Encoder, self).__init__()\n","\n","        # Hyperparameters\n","        self.input_size = PARAM[\"encoder_input_size\"]\n","        self.embedding_size = PARAM[\"embedding_size\"]\n","        self.hidden_size = PARAM[\"hidden_size\"]\n","        self.num_layers = PARAM[\"num_layers\"]\n","        self.drop_prob = PARAM[\"drop_prob\"]\n","        self.cell_type = PARAM[\"cell_type\"]\n","        self.bidirectional = PARAM[\"bidirectional\"]\n","\n","        # Layers\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n","\n","        # Select RNN cell based on cell_type\n","        cell_map = {\n","        \"LSTM\": nn.LSTM,\n","        \"GRU\": nn.GRU,\n","        \"RNN\": nn.RNN\n","        }\n","        self.cell = cell_map[self.cell_type](\n","            self.embedding_size, self.hidden_size, self.num_layers,\n","            dropout=self.drop_prob, bidirectional=self.bidirectional\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the Encoder.\n","        Args:\n","            x : Input sequence of word indices.\n","        Returns:\n","            torch.Tensor or tuple : Hidden state (or hidden & cell states for LSTMs)\n","        \"\"\"\n","\n","        embedding = self.embedding(x) # embadding layer \n","        drops = self.dropout(embedding) # Dropout on embadding \n","        if self.cell_type == \"RNN\" or self.cell_type == \"GRU\": \n","            _, hidden = self.cell(drops) \n","            return hidden\n","        elif self.cell_type == \"LSTM\":\n","            _, (hidden, cells) = self.cell(drops)\n","            return hidden, cells\n","        else:\n","            raise ValueError(f\"Invalid RNN cell type: {self.cell_type}\") # Raise a error on invalid cell type\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Decoder** "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:02.371728Z","iopub.status.busy":"2024-05-11T18:47:02.371235Z","iopub.status.idle":"2024-05-11T18:47:02.520101Z","shell.execute_reply":"2024-05-11T18:47:02.518892Z","shell.execute_reply.started":"2024-05-11T18:47:02.371685Z"},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    \"\"\"\n","    Decoder class for sequence-to-sequence models.\n","\n","    Args:\n","        PARAM (dict): Decoder hyperparameters.\n","            - input_size (int): Size of the decoder vocabulary.\n","            - embedding_size (int): Dimensionality of word embeddings.\n","            - hidden_size (int): Size of the hidden state in RNN cells.\n","            - output_size (int): Size of the output vocabulary.\n","            - num_layers (int): Number of stacked RNN layers.\n","            - drop_prob (float): Dropout probability for regularization.\n","            - cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n","            - bidirectional (bool): Whether to use a bidirectional RNN.\n","    \"\"\"\n","\n","    def __init__(self, PARAM):\n","        super(Decoder, self).__init__()\n","\n","        # Hyperparameters\n","        self.input_size = PARAM[\"decoder_input_size\"]\n","        self.embedding_size = PARAM[\"embedding_size\"]\n","        self.hidden_size = PARAM[\"hidden_size\"]\n","        self.output_size = PARAM[\"decoder_output_size\"]\n","        self.num_layers = PARAM[\"num_layers\"]\n","        self.drop_prob = PARAM[\"drop_prob\"]\n","        self.cell_type = PARAM[\"cell_type\"]\n","        self.bidirectional = PARAM[\"bidirectional\"]\n","\n","        # Layers\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n","        self.cell_map = {\n","            \"LSTM\": nn.LSTM,\n","            \"GRU\": nn.GRU,\n","            \"RNN\": nn.RNN\n","        }\n","        self.cell = self.cell_map[self.cell_type](\n","            self.embedding_size, self.hidden_size, self.num_layers,\n","            dropout=self.drop_prob, bidirectional=self.bidirectional\n","        )\n","\n","        # Final linear layer for output prediction\n","        self.fc = nn.Linear(self.hidden_size * (2 if self.bidirectional else 1), self.output_size)\n","\n","    def forward(self, x, hidden, cell=None):\n","        \"\"\"\n","        Forward pass of the Decoder.\n","\n","        Args:\n","            x (torch.Tensor): Input sequence of word indices (single token for teacher forcing).\n","            hidden (torch.Tensor): Hidden state from the encoder.\n","            cell (torch.Tensor, optional): Cell state for LSTMs (default: None).\n","\n","        Returns:\n","            tuple(torch.Tensor): Predicted output logits, hidden state (and cell state for LSTMs).\n","        \"\"\"\n","\n","        x = x.unsqueeze(0)  # Add batch dimension for single token\n","        embedding = self.embedding(x)\n","        drops = self.dropout(embedding)\n","\n","        if self.cell_type == \"RNN\" or self.cell_type == \"GRU\":\n","            outputs, hidden = self.cell(drops, hidden)\n","        elif self.cell_type == \"LSTM\":\n","            outputs, (hidden, cell) = self.cell(drops, (hidden, cell))\n","        predictions = self.fc(outputs).squeeze(0)  # Remove batch dimension\n","\n","        if self.cell_type == \"LSTM\":\n","            predictions = F.log_softmax(predictions, dim=1)\n","            return predictions, hidden, cell\n","        return predictions, hidden\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Seq2Seq Class**"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:02.727037Z","iopub.status.busy":"2024-05-11T18:47:02.726504Z","iopub.status.idle":"2024-05-11T18:47:02.741168Z","shell.execute_reply":"2024-05-11T18:47:02.739978Z","shell.execute_reply.started":"2024-05-11T18:47:02.727003Z"},"trusted":true},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    \"\"\"\n","    Seq2Seq model for sequence-to-sequence tasks.\n","\n","    Args:\n","        encoder (Encoder): Encoder module.\n","        decoder (Decoder): Decoder module.\n","        param (dict): Model hyperparameters.\n","            - tfr (float): Teacher forcing ratio for training.\n","        processed_data (dict) : containing all information of processed data\n","    \"\"\"\n","\n","    def __init__(self, encoder, decoder, param, p_data):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.teacher_forcing_ratio = param[\"tfr\"]  # Teacher forcing ratio\n","        self.processed_data = p_data\n","\n","    def forward(self, src, target):\n","        \"\"\"\n","        Forward pass of the Seq2Seq model.\n","\n","        Args:\n","            src (torch.Tensor): Source sequence of word indices.\n","            target (torch.Tensor): Target sequence of word indices.\n","\n","        Returns:\n","            torch.Tensor: Predicted output logits for each target word.\n","        \"\"\"\n","\n","        batch_size = src.shape[1]\n","        target_len = target.shape[0]\n","        target_vocab_size = self.processed_data[\"output_corpus_length\"]\n","\n","        # Initialize outputs tensor\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","\n","        # Get encoder hidden state(s)\n","        if self.encoder.cell_type == \"LSTM\":\n","            encoder_hidden, cell = self.encoder(src)\n","        elif self.encoder.cell_type == \"GRU\" or self.encoder.cell_type == \"RNN\":\n","            encoder_hidden = self.encoder(src)\n","\n","        # Start with first target word\n","        x = target[0]\n","\n","        for t in range(1, target_len):\n","            # Decode with teacher forcing or predicted output\n","            if self.encoder.cell_type == \"LSTM\":\n","                y, encoder_hidden, cell = self.decoder(x, encoder_hidden, cell) \n","            else:\n","                y, encoder_hidden = self.decoder(x, encoder_hidden, None)  \n","\n","            outputs[t] = y\n","            if random.random() < self.teacher_forcing_ratio:\n","                x = target[t]\n","            else:\n","                x = y.argmax(dim=1)\n","\n","        return outputs\n"]},{"cell_type":"markdown","metadata":{},"source":["## **Setting Optimizer**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:03.071537Z","iopub.status.busy":"2024-05-11T18:47:03.071125Z","iopub.status.idle":"2024-05-11T18:47:03.079894Z","shell.execute_reply":"2024-05-11T18:47:03.078669Z","shell.execute_reply.started":"2024-05-11T18:47:03.071504Z"},"trusted":true},"outputs":[],"source":["def set_optimizer(name, model, learning_rate):\n","    \"\"\"\n","    Creates an optimizer object based on the specified name and learning rate.\n","    Args:\n","        name (str): Name of the optimizer (e.g., \"adam\", \"sgd\", \"rmsprop\", \"adagrad\").\n","        model (nn.Module): The PyTorch model to be optimized.\n","        learning_rate (float): The learning rate to use for training.\n","    Returns:\n","        torch.optim.Optimizer: The created optimizer object.\n","    \"\"\"\n","\n","    # Define the optimizer based on the provided name\n","    optimizer = None\n","    if name == \"adam\":\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    elif name == \"sgd\":\n","        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","    elif name == \"rmsprop\":\n","        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n","    elif name == \"adagrad\":\n","        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n","    else:\n","        # Raise an error if the optimizer name is invalid\n","        raise ValueError(f\"Invalid optimizer name: {name}\")\n","\n","    # Ensure an optimizer was created\n","    if optimizer is None:\n","        raise ValueError(\"Failed to create optimizer. Please check the provided name.\")\n","\n","    return optimizer\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.008958,"end_time":"2024-04-22T12:27:48.957549","exception":false,"start_time":"2024-04-22T12:27:48.948591","status":"completed"},"tags":[]},"source":["## **BEAM SEARCH**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:03.426112Z","iopub.status.busy":"2024-05-11T18:47:03.425690Z","iopub.status.idle":"2024-05-11T18:47:03.445743Z","shell.execute_reply":"2024-05-11T18:47:03.444279Z","shell.execute_reply.started":"2024-05-11T18:47:03.426080Z"},"trusted":true},"outputs":[],"source":["def beam_search(params, model, word, device, processed_data):\n","    \"\"\"\n","    Beam search decoding for sequence-to-sequence models.\n","\n","    Args:\n","        params (dict): Model hyperparameters.\n","            - encoder_cell_type (str): Type of RNN cell (LSTM, GRU, RNN).\n","            - beam_width (int): Beam width for beam search decoding.\n","            - length_penalty (float): Penalty for longer sequences.\n","        model (nn.Module): Seq2Seq model for sequence translation.\n","        word (str): Input word to translate.\n","        device (torch.device): Device to use for computations (CPU or GPU).\n","        max_encoder_length (int): Maximum length of the encoder input sequence.\n","        input_corpus_dict (dict): Dictionary mapping input characters to integer indices.\n","        output_corpus_dict (dict): Dictionary mapping integer indices to output characters.\n","        reverse_output_corpus (dict): Dictionary mapping output characters to integer indices (for reversing prediction).\n","\n","    Returns:\n","        str: Translated sentence.\n","    \"\"\"\n","\n","    input_corpus_dict = processed_data[\"input_corpus_dict\"]\n","    output_corpus_dict = processed_data[\"output_corpus_dict\"]\n","    max_encoder_length = processed_data[\"max_encoder_length\"]\n","    reversed_output_corpus = processed_data[\"reversed_output_corpus\"]\n","    # Preprocess input sentence\n","    data = torch.zeros((max_encoder_length + 1, 1), dtype=torch.int32).to(device)\n","    for i, char in enumerate(word):\n","        data[i, 0] = input_corpus_dict[char]\n","    data[i + 1, 0] = input_corpus_dict['$']  # Add end-of-sentence marker\n","\n","    # Encode input sentence\n","    with torch.no_grad():\n","        if params[\"cell_type\"] == \"LSTM\":\n","            hidden, cell = model.encoder(data)\n","        else:\n","            hidden = model.encoder(data)\n","\n","        # Initialize beam search\n","        start_token = output_corpus_dict['#']  # Start-of-sentence symbol\n","        initial_sequence = torch.tensor([start_token]).to(device)\n","        hidden = hidden.unsqueeze(0)  # Add batch dimension\n","        beam = [(0.0, initial_sequence, hidden)]  # List of (score, sequence, hidden state) tuples\n","\n","    # Decode loop\n","        for _ in range(len(output_corpus_dict)):\n","            candidates = []  # List for storing candidate sequences\n","            for score, seq, hidden in beam:\n","                # Check for end-of-sentence token\n","                if seq[-1].item() == output_corpus_dict['$']:\n","                    candidates.append((score, seq, hidden))\n","                    continue\n","\n","                # Get last token and hidden state\n","                last_token = seq[-1].unsqueeze(0).to(device)\n","                hidden = hidden.squeeze(0)\n","\n","                # Decode step with last token\n","                if params[\"cell_type\"] == \"LSTM\":\n","                    output, hidden, cell = model.decoder(last_token, hidden, cell)\n","                else:\n","                    output, hidden = model.decoder(last_token, hidden, None)\n","\n","            # Get top-k probable tokens\n","                probabilities = F.softmax(output, dim=1)\n","                topk_probs, topk_tokens = torch.topk(probabilities, k=params[\"beam_width\"])\n","\n","                # Expand beam with top-k candidate sequences\n","                for prob, token in zip(topk_probs[0], topk_tokens[0]):\n","                    new_seq = torch.cat((seq, token.unsqueeze(0)), dim=0)\n","                    length_penalty = ((len(new_seq) - 1) / 5) ** params[\"length_penalty\"]\n","                    candidate_score = score + torch.log(prob).item() / length_penalty\n","                    candidates.append((candidate_score, new_seq, hidden.unsqueeze(0)))\n","\n","            # Select top-k beam candidates for next iteration\n","            beam = heapq.nlargest(params[\"beam_width\"], candidates, key=lambda x: x[0])\n","\n","        # Get best sequence from beam search\n","        best_score, best_sequence, _ = max(beam, key=lambda x: x[0])\n","\n","        # Convert predicted token indices to characters and reverse order\n","        translated_sentence = ''.join([reversed_output_corpus[token.item()] for token in best_sequence[1:]])[:-1]  # Remove start token and end token\n","\n","        return translated_sentence\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:03.593679Z","iopub.status.busy":"2024-05-11T18:47:03.592686Z","iopub.status.idle":"2024-05-11T18:47:03.605991Z","shell.execute_reply":"2024-05-11T18:47:03.604610Z","shell.execute_reply.started":"2024-05-11T18:47:03.593641Z"},"trusted":true},"outputs":[],"source":["def run_epoch(model, data_loader, optimizer, criterion, processed_data):\n","    \"\"\"\n","    Train the Seq2Seq model for one epoch.\n","\n","    Args:\n","        model (nn.Module): Seq2Seq model to train.\n","        data_loader (List): List containing training_data.\n","        optimizer (Optimizer): Optimizer for updating model parameters.\n","        criterion (nn.Module): Loss function for calculating training loss.\n","\n","    Returns:\n","        tuple(float, float): Training accuracy and average loss.\n","    \"\"\"\n","\n","    model.train()  # Set model to training mode\n","    total_loss, total_words, correct_predictions = 0, 0, 0\n","\n","    with tqdm(total=len(data_loader[0]), desc='Training') as pbar:  # Gradient accumulation\n","        for _ , (source, target) in enumerate(zip(data_loader[0], data_loader[1])):\n","            source, target = source.to(device), target.to(device)  # Move data to device\n","            optimizer.zero_grad()\n","\n","            # Forward pass\n","            output = model(source, target)\n","            target = target.reshape(-1)  # Reshape target for loss calculation\n","            output = output.reshape(-1, output.shape[2])  # Reshape output\n","            \n","            #Ignore the padding\n","            pad_mask = (target != processed_data['output_corpus_dict'][''])\n","            target = target[pad_mask]\n","            output = output[pad_mask]\n","\n","            # Calculate loss\n","            loss = criterion(output, target)\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Gradient clipping\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","            optimizer.step()  # Update model parameters\n","\n","            # Calculate total loss, total words, correct_predictions\n","            total_loss += loss.item()\n","            total_words += target.size(0)\n","            correct_predictions += torch.sum(torch.argmax(output, dim = 1) == target).item()\n","            pbar.update(1)\n","\n","    # Calculate Accuracy and Avg Loss\n","    accuracy = correct_predictions / total_words\n","    avg_loss = total_loss / len(data_loader[0])\n","\n","    return accuracy, avg_loss\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:03.741301Z","iopub.status.busy":"2024-05-11T18:47:03.740880Z","iopub.status.idle":"2024-05-11T18:47:03.754101Z","shell.execute_reply":"2024-05-11T18:47:03.752839Z","shell.execute_reply.started":"2024-05-11T18:47:03.741269Z"},"trusted":true},"outputs":[],"source":["def evaluate_character_level(model, val_data_loader, loss_fn, processed_data):\n","    \"\"\"\n","    Evaluate the Seq2Seq model on character-level data.\n","\n","    Args:\n","        model (nn.Module): Seq2Seq model to evaluate.\n","        val_data_loader (DataLoader): Data loader for validation data.\n","        loss_fn (nn.Module): Loss function for calculating validation loss.\n","\n","    Returns:\n","        tuple(float, float): Validation accuracy and average loss.\n","    \"\"\"\n","\n","    model.eval()  # Set model to evaluation mode\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_words = 0\n","        correct_predictions = 0\n","\n","        with tqdm(total=len(val_data_loader[0]), desc='Validation') as pbar:\n","            for src, tar in zip(val_data_loader[0], val_data_loader[1]):\n","                target, source = tar.to(device), src.to(device)\n","\n","                # Apply model\n","                output = model(source, target)\n","\n","                # Reshape target and output\n","                target = target.reshape(-1)\n","                output = output.reshape(-1, output.shape[2])\n","                \n","                # Ignore the padding \n","                pad_mask = (target != processed_data['output_corpus_dict'][''])\n","                target = target[pad_mask]\n","                output = output[pad_mask]\n","\n","                #Calculate total_loss, total_words, correct_predictions\n","                val_loss = loss_fn(output, target)\n","                total_loss += val_loss.item()\n","                total_words += target.size(0)\n","                correct_predictions += torch.sum(torch.argmax(output, dim=1) == target).item()\n","                pbar.update(1)\n","        \n","    accuracy = correct_predictions / total_words\n","    avg_loss = total_loss / len(val_data_loader[0])\n","\n","    return accuracy, avg_loss\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:03.895742Z","iopub.status.busy":"2024-05-11T18:47:03.894640Z","iopub.status.idle":"2024-05-11T18:47:03.909715Z","shell.execute_reply":"2024-05-11T18:47:03.907821Z","shell.execute_reply.started":"2024-05-11T18:47:03.895702Z"},"trusted":true},"outputs":[],"source":["def evaluate_model_beam_search(params, model, device, processed_data):\n","    \"\"\"\n","    Evaluates the model using beam search and returns accuracy and correct predictions.\n","\n","    Args:\n","        model (torch.nn.Module): The machine translation model to evaluate.\n","        val_data (torch.Tensor): The validation data tensor.\n","        vx (list): List of source words for beam search.\n","        vy (list): List of target words for beam search.\n","        device (str): Device to use for computation (e.g., 'cpu' or 'cuda').\n","        processed_data (dict): Preprocessed data dictionary.\n","\n","    Returns:\n","        tuple: A tuple containing validation accuracy (float) and correct predictions (int).\n","    \"\"\"\n","\n","# Set the model to evaluation mode\n","    model.eval()\n","\n","    # Disable gradient computation during inference\n","    with torch.no_grad():\n","        # Initialize counters\n","        total_words = 0\n","        correct_predictions = 0\n","        \n","        # Iterate through the validation data with tqdm progress bar\n","        with tqdm(total=len(processed_data[\"val_x\"]), desc='Beam_Search') as pbar:\n","            for word, target_word in zip(processed_data[\"val_x\"], processed_data[\"val_y\"]):\n","                # Increment the total words counter\n","                total_words += 1\n","                \n","                # Perform beam search to predict the next word\n","                predicted_word = beam_search(params, model, word, device, processed_data)\n","#                 print(target_word, predicted_word)\n","                # Check if the predicted word matches the target word\n","                if predicted_word == target_word[1:-1]:  # Remove start and end tokens\n","                    correct_predictions += 1\n","                \n","                # Update the progress bar\n","                pbar.update(1)\n","\n","    # Calculate accuracy\n","    accuracy = correct_predictions / total_words\n","\n","    # Return accuracy and number of correct predictions\n","    return accuracy, correct_predictions\n","\n"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009195,"end_time":"2024-04-22T12:27:49.012983","exception":false,"start_time":"2024-04-22T12:27:49.003788","status":"completed"},"tags":[]},"source":["## **Train Using Beam Search**"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:04.260242Z","iopub.status.busy":"2024-05-11T18:47:04.259868Z","iopub.status.idle":"2024-05-11T18:47:04.275751Z","shell.execute_reply":"2024-05-11T18:47:04.274476Z","shell.execute_reply.started":"2024-05-11T18:47:04.260212Z"},"papermill":{"duration":0.009035,"end_time":"2024-04-22T12:27:49.031338","exception":false,"start_time":"2024-04-22T12:27:49.022303","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def training(PARAM, processed_data, device, wandb_log = 0):\n","    # initilize wandb with project\n","    if wandb_log == 1:\n","        wandb.init(project = 'CS6910-Assignment3')\n","        wandb.run.name = 'Training'\n","    \n","    # Set Learning Rate, epochsm batch_size\n","    learning_rate = PARAM[\"learning_rate\"]\n","    epochs = PARAM[\"epochs\"]\n","    batch_size = PARAM[\"batch_size\"]\n","\n","    # Copy encoder and decoder to device\n","    encoder = Encoder(PARAM).to(device)\n","    decoder = Decoder(PARAM).to(device)\n","\n","#     # Initialize model\n","    model = Seq2Seq(encoder, decoder, PARAM, processed_data).to(device)\n","    print(model)\n","\n","    # Define loss function and optimizer\n","    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n","    optimizer = set_optimizer(PARAM[\"optimizer\"], model, learning_rate)\n","\n","    # Split dataset into batches\n","    train_batches_x = torch.split(processed_data[\"train_input\"], batch_size, dim=1)\n","    train_batches_y = torch.split(processed_data[\"train_output\"], batch_size, dim=1)\n","    val_batches_x = torch.split(processed_data[\"val_input\"], batch_size, dim=1)\n","    val_batches_y = torch.split(processed_data[\"val_output\"], batch_size, dim=1)\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        print(f\"Epoch :: {epoch+1}/{epochs}\")\n","        \n","        # Train the model on training data\n","        data_loader = [train_batches_x, train_batches_y]\n","        accuracy, avg_loss = run_epoch(model, data_loader, optimizer, loss_function, processed_data)  # Average loss per batch\n","\n","        # Evaluate model character wise\n","        val_data_loader = [val_batches_x, val_batches_y]\n","        val_accuracy, val_avg_loss = evaluate_character_level(model, val_data_loader, loss_function, processed_data)\n","        \n","        # Evaluate model word wise\n","        val_accuracy_beam, val_correct_pred_beam = evaluate_model_beam_search(PARAM, model, device, processed_data)\n","        total_words = processed_data[\"val_input\"].shape[1] \n","\n","        # print epochs\n","        print(f\"Epoch : {epoch+1} Train Accuracy: {accuracy*100:.4f}, Train Loss: {avg_loss:.4f}\\nValidation Accuracy: {val_accuracy*100:.4f}, Validation Loss: {val_avg_loss:.4f}, \\nValidation Acc. With BeamSearch: {val_accuracy_beam*100:.4f}, Correctly Predicted : {val_correct_pred_beam}/{total_words}\")\n","\n","        # Log on wandb\n","        if wandb_log:\n","            wandb.log(\n","                    {\n","                        'epoch': epoch+1,\n","                        'training_loss' : avg_loss,\n","                        'training_accuracy' : accuracy,\n","                        'validation_loss' : val_avg_loss,\n","                        'validation_accuracy_using_char' : val_accuracy,\n","                        'validation_accuracy_using_word' : val_accuracy_beam,\n","                        'correctly_predicted' : val_correct_pred_beam\n","                    }\n","                )\n","    return model, val_accuracy_beam"]},{"cell_type":"markdown","metadata":{},"source":["## **Get Data**"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:47:04.615360Z","iopub.status.busy":"2024-05-11T18:47:04.614531Z","iopub.status.idle":"2024-05-11T18:47:05.738354Z","shell.execute_reply":"2024-05-11T18:47:05.737202Z","shell.execute_reply.started":"2024-05-11T18:47:04.615325Z"},"trusted":true},"outputs":[],"source":["processed_data = preprocess_data('hin')"]},{"cell_type":"markdown","metadata":{},"source":["## **HYPER PARAMETERS**"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:49:30.163904Z","iopub.status.busy":"2024-05-11T18:49:30.162703Z","iopub.status.idle":"2024-05-11T18:49:30.170031Z","shell.execute_reply":"2024-05-11T18:49:30.168946Z","shell.execute_reply.started":"2024-05-11T18:49:30.163864Z"},"trusted":true},"outputs":[],"source":["HYPER_PARAM = {\n","    \"encoder_input_size\": processed_data[\"input_corpus_length\"],\n","    \"embedding_size\": 256,\n","    \"hidden_size\": 512,\n","    \"num_layers\": 2,\n","    \"drop_prob\": 0.3,\n","    \"cell_type\": \"LSTM\",\n","    \"decoder_input_size\": processed_data[\"output_corpus_length\"],\n","    \"decoder_output_size\": processed_data[\"output_corpus_length\"],\n","    \"beam_width\" : 1,\n","    \"length_penalty\" : 0.6,\n","    \"bidirectional\" : True,\n","    \"learning_rate\" : 0.01,\n","    \"batch_size\" : 32,\n","    \"epochs\" : 10,\n","    \"optimizer\" : \"adagrad\",\n","    \"tfr\" : 0.7,\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## **Training Model on Hyper Parameters**"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T18:49:35.636639Z","iopub.status.busy":"2024-05-11T18:49:35.635543Z","iopub.status.idle":"2024-05-11T19:12:27.147508Z","shell.execute_reply":"2024-05-11T19:12:27.146492Z","shell.execute_reply.started":"2024-05-11T18:49:35.636600Z"},"papermill":{"duration":0.017322,"end_time":"2024-04-22T12:27:49.170183","exception":false,"start_time":"2024-04-22T12:27:49.152861","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (embedding): Embedding(29, 256)\n","    (cell): LSTM(256, 512, num_layers=2, dropout=0.3, bidirectional=True)\n","  )\n","  (decoder): Decoder(\n","    (dropout): Dropout(p=0.3, inplace=False)\n","    (embedding): Embedding(68, 256)\n","    (cell): LSTM(256, 512, num_layers=2, dropout=0.3, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=68, bias=True)\n","  )\n",")\n","Epoch :: 1/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:34<00:00, 16.87it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 50.25it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1 Train Accuracy: 61.9472, Train Loss: 1.3652\n","Validation Accuracy: 71.4453, Validation Loss: 1.0519, \n","Validation Acc. With BeamSearch: 30.3711, Correctly Predicted : 1244/4096\n","Epoch :: 2/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:34<00:00, 16.92it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 49.24it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 101.83it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 2 Train Accuracy: 73.4053, Train Loss: 0.9681\n","Validation Accuracy: 74.0046, Validation Loss: 0.9766, \n","Validation Acc. With BeamSearch: 35.2539, Correctly Predicted : 1444/4096\n","Epoch :: 3/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:33<00:00, 17.04it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 48.75it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 3 Train Accuracy: 76.3847, Train Loss: 0.8737\n","Validation Accuracy: 74.5616, Validation Loss: 0.9633, \n","Validation Acc. With BeamSearch: 38.5986, Correctly Predicted : 1581/4096\n","Epoch :: 4/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:33<00:00, 17.04it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 48.67it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 4 Train Accuracy: 78.1478, Train Loss: 0.8192\n","Validation Accuracy: 75.0985, Validation Loss: 0.9501, \n","Validation Acc. With BeamSearch: 40.7227, Correctly Predicted : 1668/4096\n","Epoch :: 5/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:34<00:00, 16.95it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 49.20it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 5 Train Accuracy: 79.4642, Train Loss: 0.7790\n","Validation Accuracy: 75.4470, Validation Loss: 0.9389, \n","Validation Acc. With BeamSearch: 41.2354, Correctly Predicted : 1689/4096\n","Epoch :: 6/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:33<00:00, 17.07it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 49.42it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 6 Train Accuracy: 80.5080, Train Loss: 0.7453\n","Validation Accuracy: 74.9729, Validation Loss: 0.9618, \n","Validation Acc. With BeamSearch: 41.0156, Correctly Predicted : 1680/4096\n","Epoch :: 7/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:33<00:00, 17.04it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 49.11it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 7 Train Accuracy: 81.6072, Train Loss: 0.7134\n","Validation Accuracy: 75.3842, Validation Loss: 0.9504, \n","Validation Acc. With BeamSearch: 41.5283, Correctly Predicted : 1701/4096\n","Epoch :: 8/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:34<00:00, 16.96it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 48.78it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 102.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 8 Train Accuracy: 82.2268, Train Loss: 0.6939\n","Validation Accuracy: 75.8498, Validation Loss: 0.9358, \n","Validation Acc. With BeamSearch: 41.8213, Correctly Predicted : 1713/4096\n","Epoch :: 9/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:33<00:00, 17.09it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 48.33it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:40<00:00, 101.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 9 Train Accuracy: 82.9881, Train Loss: 0.6694\n","Validation Accuracy: 75.9297, Validation Loss: 0.9372, \n","Validation Acc. With BeamSearch: 41.9434, Correctly Predicted : 1718/4096\n","Epoch :: 10/10\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 1600/1600 [01:34<00:00, 16.99it/s]\n","Validation: 100%|██████████| 128/128 [00:02<00:00, 48.07it/s]\n","Beam_Search: 100%|██████████| 4096/4096 [00:39<00:00, 102.61it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch : 10 Train Accuracy: 83.7466, Train Loss: 0.6463\n","Validation Accuracy: 76.4296, Validation Loss: 0.9229, \n","Validation Acc. With BeamSearch: 42.1143, Correctly Predicted : 1725/4096\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model, acc = training(HYPER_PARAM, processed_data, device, wandb_log = 0)"]},{"cell_type":"markdown","metadata":{},"source":["## **Sweep Config**"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T19:13:37.161975Z","iopub.status.busy":"2024-05-11T19:13:37.161564Z","iopub.status.idle":"2024-05-11T19:13:37.171088Z","shell.execute_reply":"2024-05-11T19:13:37.170085Z","shell.execute_reply.started":"2024-05-11T19:13:37.161941Z"},"papermill":{"duration":0.020451,"end_time":"2024-04-22T12:27:49.200094","exception":false,"start_time":"2024-04-22T12:27:49.179643","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sweep_config = {\n","            'name': 'sweep-bayes-1',\n","            'method': 'bayes',\n","            'metric': { 'goal': 'maximize','name': 'Accuracy'},\n","            'parameters': \n","                {\n","                    'epochs': {'values': [10]},\n","                    'cell_type': {'values': ['RNN', 'LSTM', 'GRU']},\n","                    'embedding_size': {'values': [128, 256, 512]},\n","                    'hidden_size': {'values': [128, 256, 512, 1024]},\n","                    'num_layers': {'values': [1, 2, 3]},\n","                    'dropout': {'values': [0.3, 0.5, 0.7]},\n","                    'optimizer' : {'values' : ['adam', 'sgd', 'rmsprop', 'adagrad']},\n","                    'learning_rate': {'values': [0.001, 0.005, 0.01, 0.1]},\n","                    'batch_size': {'values': [32, 64]},\n","                    'teacher_fr' : {'values': [0.3, 0.5, 0.7]},\n","                    'length_penalty' : {'values': [0.4, 0.5, 0.6]},\n","                    'bi_dir' : {'values': [True, False]},\n","                    'beam_width': {'values': [1, 2, 3]}\n","                }\n","            }"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T19:13:37.328361Z","iopub.status.busy":"2024-05-11T19:13:37.327996Z","iopub.status.idle":"2024-05-11T19:13:37.334178Z","shell.execute_reply":"2024-05-11T19:13:37.332990Z","shell.execute_reply.started":"2024-05-11T19:13:37.328333Z"},"papermill":{"duration":0.021012,"end_time":"2024-04-22T12:27:49.230944","exception":false,"start_time":"2024-04-22T12:27:49.209932","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def train():\n","    var1 = wandb.init(project=\"CS6910-Assignment3\")\n","    var2 = var1.config\n","   \n","    wandb.run.name = (f\"cell_type:{var2.cell_type}_epochs:{var2.epochs}_lr:{var2.learning_rate}_batch_size:{var2.batch_size}_beam_width:{var2.beam_width}_opt:{var2.optimizer}_dropout:{var2.dropout}_teacher_fr:{var2.teacher_fr}_embadding_size:{var2.embedding_size}\")\n","    \n","    HYPER_PARAM = {\n","    \"encoder_input_size\": processed_data[\"input_corpus_length\"],\n","    \"embedding_size\": var2.embedding_size,\n","    \"hidden_size\": var2.hidden_size,\n","    \"num_layers\": var2.num_layers,\n","    \"drop_prob\": var2.dropout,\n","    \"cell_type\": var2.cell_type,\n","    \"decoder_input_size\": processed_data[\"output_corpus_length\"],\n","    \"decoder_output_size\": processed_data[\"output_corpus_length\"],\n","    \"beam_width\" : var2.beam_width,\n","    \"length_penalty\" : var2.length_penalty,\n","    \"bidirectional\" : var2.bi_dir,\n","    \"learning_rate\" : var2.learning_rate,\n","    \"batch_size\" : var2.batch_size,\n","    \"epochs\" : var2.epochs,\n","    \"optimizer\" : var2.optimizer,\n","    \"tfr\" : var2.teacher_fr,\n","}\n","\n","    model, accuracy = training(HYPER_PARAM, wandb_log = 1)\n","    wandb.log({\n","                \"Accuracy\" : accuracy\n","            })"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T19:13:37.498770Z","iopub.status.busy":"2024-05-11T19:13:37.497950Z","iopub.status.idle":"2024-05-11T19:13:37.503304Z","shell.execute_reply":"2024-05-11T19:13:37.501936Z","shell.execute_reply.started":"2024-05-11T19:13:37.498714Z"},"papermill":{"duration":10628.113884,"end_time":"2024-04-22T15:24:57.354431","exception":false,"start_time":"2024-04-22T12:27:49.240547","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sweep_id = wandb.sweep(sweep_config, project=\"CS6910-Assignment3\")\n","wandb.agent(sweep_id, train, count = 2)\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["## **Predictions on Test Data in CSV File**"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T19:13:38.975239Z","iopub.status.busy":"2024-05-11T19:13:38.974360Z","iopub.status.idle":"2024-05-11T19:13:38.985984Z","shell.execute_reply":"2024-05-11T19:13:38.984815Z","shell.execute_reply.started":"2024-05-11T19:13:38.975199Z"},"trusted":true},"outputs":[],"source":["def store_prediction_in_csv_file(HYPER_PARAM, model, device, processed_data):\n","    # Initialize counters for correct and incorrect predictions\n","    total_correct, total_incorrect = 0, 0\n","    \n","    # Initialize lists to store results\n","    result, decoded_output, correct_output, input_word = [], [], [], []\n","    \n","    # Iterate over each word and its correct transliteration\n","    for word, correct_transliteration in zip(processed_data[\"test_x\"], processed_data[\"test_y\"]):\n","        # Generate output sequence using beam search\n","        output_sequence = beam_search(HYPER_PARAM, model, word[:-1], device, processed_data)\n","        \n","        # Check if the output sequence matches the correct transliteration\n","        if output_sequence != correct_transliteration[1:-1]:\n","            total_incorrect += 1\n","            result.append(\"Incorrect\")\n","        else:\n","            total_correct += 1\n","            result.append(\"Correct\")\n","        \n","        # Append data to lists\n","        decoded_output.append(output_sequence)\n","        correct_output.append(correct_transliteration[1:-1])\n","        input_word.append(word[:-1])\n","    \n","    # Print total correct and incorrect predictions\n","    print(total_correct, total_incorrect)\n","    \n","    # Create a dictionary to store data\n","    grid = {'Input_Word': input_word, 'Decoded_Output': decoded_output, 'True_Output': correct_output, \"Match Result\": result}\n","    \n","    # Define the path to save the CSV file\n","    _path = '/kaggle/working/predictions_vanilla.csv'\n","    \n","    # Create a DataFrame from the dictionary\n","    df = pd.DataFrame(grid)\n","    \n","    # Save the DataFrame to a CSV file\n","    df.to_csv(_path, index=False, header=True)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-11T19:13:45.241683Z","iopub.status.busy":"2024-05-11T19:13:45.241305Z","iopub.status.idle":"2024-05-11T19:14:26.506082Z","shell.execute_reply":"2024-05-11T19:14:26.504934Z","shell.execute_reply.started":"2024-05-11T19:13:45.241652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1624 2472\n"]}],"source":["store_prediction_in_csv_file(HYPER_PARAM, model, device, processed_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4830707,"sourceId":8164175,"sourceType":"datasetVersion"},{"datasetId":4844106,"sourceId":8181791,"sourceType":"datasetVersion"},{"datasetId":4861591,"sourceId":8205199,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"papermill":{"default_parameters":{},"duration":10667.002796,"end_time":"2024-04-22T15:25:23.121216","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-22T12:27:36.118420","version":"2.5.0"}},"nbformat":4,"nbformat_minor":4}
