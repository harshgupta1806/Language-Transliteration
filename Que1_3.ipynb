{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.009311,"end_time":"2024-04-22T12:27:39.017921","exception":false,"start_time":"2024-04-22T12:27:39.008610","status":"completed"},"tags":[]},"source":["## **Import Libraries**"]},{"cell_type":"code","execution_count":35,"id":"ffba993d","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:43.196977Z","iopub.status.busy":"2024-04-23T15:46:43.196572Z","iopub.status.idle":"2024-04-23T15:46:43.203566Z","shell.execute_reply":"2024-04-23T15:46:43.202378Z","shell.execute_reply.started":"2024-04-23T15:46:43.196948Z"},"papermill":{"duration":5.240219,"end_time":"2024-04-22T12:27:44.267093","exception":false,"start_time":"2024-04-22T12:27:39.026874","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["import torch\n","import csv\n","import torch.nn as nn\n","import random\n","import numpy as np\n","import torch.optim as optim\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch.autograd import Variable \n","from tqdm import tqdm\n","import random\n","import torch.nn.functional as F\n","import heapq\n","import wandb"]},{"cell_type":"markdown","id":"16746e5b","metadata":{"papermill":{"duration":0.008822,"end_time":"2024-04-22T12:27:44.285178","exception":false,"start_time":"2024-04-22T12:27:44.276356","status":"completed"},"tags":[]},"source":["## **SET DEVICE (CPU / GPU)**"]},{"cell_type":"code","execution_count":36,"id":"bf6b4d73","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:43.205623Z","iopub.status.busy":"2024-04-23T15:46:43.205336Z","iopub.status.idle":"2024-04-23T15:46:43.218508Z","shell.execute_reply":"2024-04-23T15:46:43.217551Z","shell.execute_reply.started":"2024-04-23T15:46:43.205598Z"},"papermill":{"duration":0.067395,"end_time":"2024-04-22T12:27:44.361097","exception":false,"start_time":"2024-04-22T12:27:44.293702","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Set Device which to use\n","def set_device():\n","    device = \"cpu\"\n","    if torch.cuda.is_available():\n","        device = \"cuda\"\n","    return device\n","\n","device = set_device()\n","print(device)"]},{"cell_type":"code","execution_count":37,"id":"492baf5f","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:43.219858Z","iopub.status.busy":"2024-04-23T15:46:43.219549Z","iopub.status.idle":"2024-04-23T15:46:46.179894Z","shell.execute_reply":"2024-04-23T15:46:46.178581Z","shell.execute_reply.started":"2024-04-23T15:46:43.219835Z"},"papermill":{"duration":3.039322,"end_time":"2024-04-22T12:27:47.409602","exception":false,"start_time":"2024-04-22T12:27:44.370280","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!wandb login 57566fbb0e091de2e298a4320d872f9a2b200d12"]},{"cell_type":"markdown","id":"e963948b","metadata":{"papermill":{"duration":0.009457,"end_time":"2024-04-22T12:27:47.428558","exception":false,"start_time":"2024-04-22T12:27:47.419101","status":"completed"},"tags":[]},"source":["## **LOAD DATA**"]},{"cell_type":"code","execution_count":38,"id":"98d55f7d","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:46.182022Z","iopub.status.busy":"2024-04-23T15:46:46.181663Z","iopub.status.idle":"2024-04-23T15:46:46.198311Z","shell.execute_reply":"2024-04-23T15:46:46.197245Z","shell.execute_reply.started":"2024-04-23T15:46:46.181992Z"},"papermill":{"duration":0.178081,"end_time":"2024-04-22T12:27:47.616014","exception":false,"start_time":"2024-04-22T12:27:47.437933","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def load_data(lan = 'hin'):\n","    train_data_path = '/kaggle/input/vocabs/Dataset/hin/hin_train.csv'\n","    test_data_path = '/kaggle/input/vocabs/Dataset/hin/hin_test.csv'\n","    val_data_path = '/kaggle/input/vocabs/Dataset/hin/hin_valid.csv'\n","    \n","    train_x = []\n","    train_y = []\n","    with open(train_data_path, 'r', encoding='utf-8') as file:\n","        csv_reader = csv.reader(file)\n","        # next(csv_reader)  # Skip the header row if it exists\n","        for row in csv_reader:\n","            train_x.append(row[0] + '$')\n","            train_y.append('#' + row[1] + '$')\n","       \n","    \n","    val_x, val_y = [], []\n","    with open(val_data_path, 'r', encoding='utf-8') as file:\n","        csv_reader = csv.reader(file)\n","        # next(csv_reader)  # Skip the header row if it exists\n","        for row in csv_reader:\n","            val_x.append(row[0] + '$')\n","            val_y.append('#' + row[1] + '$')\n","    \n","    test_x, test_y = [], []\n","    with open(test_data_path, 'r', encoding='utf-8') as file:\n","        csv_reader = csv.reader(file)\n","        # next(csv_reader)  # Skip the header row if it exists\n","        for row in csv_reader:\n","            test_x.append(row[0] + '$')\n","            test_y.append('#' + row[1] + '$')\n","\n","    # Conversion in NP Array\n","    train_x, train_y = np.array(train_x), np.array(train_y)\n","    val_x, val_y = np.array(val_x), np.array(val_y)\n","    test_x, test_y = np.array(test_x), np.array(test_y)\n","\n","    #get size of data\n","    max_decoder_length_train = np.max(np.array([len(s) for s in train_y]))\n","    max_decoder_length_val = np.max(np.array([len(s) for s in val_y]))\n","    max_decoder_length_test = np.max(np.array([len(s) for s in test_y]))\n","    max_decoder_length = max(max_decoder_length_train, max(max_decoder_length_val, max_decoder_length_test))\n","\n","    max_encoder_length_train = np.max(np.array([len(s) for s in train_x]))\n","    max_encoder_length_val = np.max(np.array([len(s) for s in val_x]))\n","    max_encoder_length_test = np.max(np.array([len(s) for s in test_x]))\n","    max_encoder_length = max(max_encoder_length_train, max(max_encoder_length_val, max_encoder_length_test))\n","\n","\n","    print(max_decoder_length)\n","    print(max_encoder_length)\n","\n","    \n","\n","# Find the maximum length\n","    return_res = {\n","        \"train_x\" : train_x,\n","        \"train_y\" : train_y,\n","        \"val_x\" : val_x,\n","        \"val_y\" : val_y,\n","        \"test_x\" : test_x,\n","        \"test_y\" : test_y,\n","        \"max_decoder_length\" : max_decoder_length,\n","        \"max_encoder_length\" : max_encoder_length,\n","    }\n","\n","    return return_res"]},{"cell_type":"code","execution_count":39,"id":"87c20ed8","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:46.201678Z","iopub.status.busy":"2024-04-23T15:46:46.201273Z","iopub.status.idle":"2024-04-23T15:46:46.417264Z","shell.execute_reply":"2024-04-23T15:46:46.416332Z","shell.execute_reply.started":"2024-04-23T15:46:46.201652Z"},"papermill":{"duration":0.245807,"end_time":"2024-04-22T12:27:47.870975","exception":false,"start_time":"2024-04-22T12:27:47.625168","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["22\n","27\n"]}],"source":["res = load_data(\"hin\")\n","tx = res[\"train_x\"]\n","ty = res[\"train_y\"]\n","vx = res[\"val_x\"]\n","vy = res[\"val_y\"]\n","tex = res[\"test_x\"]\n","tey = res[\"test_y\"]\n","max_decoder_length = res[\"max_decoder_length\"]\n","max_encoder_length = res[\"max_encoder_length\"]\n","train_len = tx.shape[0]\n","val_len = vx.shape[0]"]},{"cell_type":"code","execution_count":40,"id":"d6b46d24","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:46.418717Z","iopub.status.busy":"2024-04-23T15:46:46.418417Z","iopub.status.idle":"2024-04-23T15:46:46.428890Z","shell.execute_reply":"2024-04-23T15:46:46.427966Z","shell.execute_reply.started":"2024-04-23T15:46:46.418692Z"},"papermill":{"duration":0.023639,"end_time":"2024-04-22T12:27:47.904160","exception":false,"start_time":"2024-04-22T12:27:47.880521","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def create_corpus(train_x, train_y, val_x, val_y, test_x, test_y):\n","\n","    english_vocab = \"#$abcdefghijklmnopqrstuvwxyz\"\n","    input_corpus_dict = {}\n","    input_corpus_dict[''] = 0\n","    index = 1\n","    for characters in english_vocab:\n","        input_corpus_dict[characters] = index\n","        index += 1\n","    \n","    output_vocab = set()\n","    for word in train_y:\n","        for characters in word:\n","            output_vocab.add(characters)\n","    for word in val_y:\n","        for characters in word:\n","            output_vocab.add(characters)\n","    for word in test_y:\n","        for characters in word:\n","            output_vocab.add(characters)\n","    output_vocab.add('')\n","    sorted_output_vocab = sorted(output_vocab)\n","\n","    output_corpus_dict = {}\n","    index = 0\n","    for characters in sorted_output_vocab:\n","        output_corpus_dict[characters] = index\n","        index += 1\n","\n","    reversed_input_corpus = {value: key for key, value in input_corpus_dict.items()}\n","    reversed_output_corpus = {value: key for key, value in output_corpus_dict.items()}\n","    return_dict = {\n","        \"input_corpus_length\" : len(english_vocab),\n","        \"output_corpus_length\" : len(output_vocab),\n","        \"input_corpus_dict\" : input_corpus_dict,\n","        \"output_corpus_dict\" : output_corpus_dict,\n","        \"reversed_input_corpus\" : reversed_input_corpus,\n","        \"reversed_output_corpus\" : reversed_output_corpus\n","    }\n","    \n","    return return_dict"]},{"cell_type":"code","execution_count":41,"id":"45e36ab8","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:46.430410Z","iopub.status.busy":"2024-04-23T15:46:46.430144Z","iopub.status.idle":"2024-04-23T15:46:46.558928Z","shell.execute_reply":"2024-04-23T15:46:46.557781Z","shell.execute_reply.started":"2024-04-23T15:46:46.430388Z"},"papermill":{"duration":0.13694,"end_time":"2024-04-22T12:27:48.051588","exception":false,"start_time":"2024-04-22T12:27:47.914648","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["28\n","68\n","{'': 0, '#': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n","{'': 0, '#': 1, '$': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'ळ': 46, 'व': 47, 'श': 48, 'ष': 49, 'स': 50, 'ह': 51, '़': 52, 'ऽ': 53, 'ा': 54, 'ि': 55, 'ी': 56, 'ु': 57, 'ू': 58, 'ृ': 59, 'ॅ': 60, 'े': 61, 'ै': 62, 'ॉ': 63, 'ॊ': 64, 'ो': 65, 'ौ': 66, '्': 67}\n","{0: '', 1: '#', 2: '$', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n","{0: '', 1: '#', 2: '$', 3: 'ँ', 4: 'ं', 5: 'ः', 6: 'अ', 7: 'आ', 8: 'इ', 9: 'ई', 10: 'उ', 11: 'ऊ', 12: 'ऋ', 13: 'ए', 14: 'ऐ', 15: 'ऑ', 16: 'ओ', 17: 'औ', 18: 'क', 19: 'ख', 20: 'ग', 21: 'घ', 22: 'ङ', 23: 'च', 24: 'छ', 25: 'ज', 26: 'झ', 27: 'ञ', 28: 'ट', 29: 'ठ', 30: 'ड', 31: 'ढ', 32: 'ण', 33: 'त', 34: 'थ', 35: 'द', 36: 'ध', 37: 'न', 38: 'प', 39: 'फ', 40: 'ब', 41: 'भ', 42: 'म', 43: 'य', 44: 'र', 45: 'ल', 46: 'ळ', 47: 'व', 48: 'श', 49: 'ष', 50: 'स', 51: 'ह', 52: '़', 53: 'ऽ', 54: 'ा', 55: 'ि', 56: 'ी', 57: 'ु', 58: 'ू', 59: 'ृ', 60: 'ॅ', 61: 'े', 62: 'ै', 63: 'ॉ', 64: 'ॊ', 65: 'ो', 66: 'ौ', 67: '्'}\n"]}],"source":["res_dict = create_corpus(tx, ty, vx, vy, tex, tey)\n","print(res_dict[\"input_corpus_length\"])\n","print(res_dict[\"output_corpus_length\"])\n","print(res_dict[\"input_corpus_dict\"])\n","print(res_dict[\"output_corpus_dict\"])\n","print(res_dict[\"reversed_input_corpus\"])\n","print(res_dict[\"reversed_output_corpus\"])\n","\n","input_corpus_length = res_dict[\"input_corpus_length\"]\n","output_corpus_length = res_dict[\"output_corpus_length\"]\n","output_corpus_dict = res_dict[\"output_corpus_dict\"]\n","input_corpus_dict = res_dict[\"input_corpus_dict\"]\n","reversed_output_corpus = res_dict[\"reversed_output_corpus\"]\n","reversed_input_corpus = res_dict[\"reversed_input_corpus\"]\n","        "]},{"cell_type":"code","execution_count":42,"id":"b76cffe6","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:46.560983Z","iopub.status.busy":"2024-04-23T15:46:46.560516Z","iopub.status.idle":"2024-04-23T15:46:46.573520Z","shell.execute_reply":"2024-04-23T15:46:46.572262Z","shell.execute_reply.started":"2024-04-23T15:46:46.560943Z"},"papermill":{"duration":0.024579,"end_time":"2024-04-22T12:27:48.085908","exception":false,"start_time":"2024-04-22T12:27:48.061329","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def create_tensor(tx, ty, vx, vy, res, dict):\n","    max_len = max(res[\"max_encoder_length\"], res[\"max_decoder_length\"])\n","    train_input = np.zeros((max_len, train_len), dtype = 'int64')\n","    train_output = np.zeros((max_len, train_len), dtype = 'int64')\n","    val_input = np.zeros((max_len, val_len), dtype = 'int64')\n","    val_output = np.zeros((max_len, val_len), dtype = 'int64')\n","\n","    print(dict[\"input_corpus_dict\"])\n","    print(dict[\"output_corpus_dict\"])\n","    word_count = 0\n","    for words in tx:\n","        index = 0\n","        for chars in words:\n","            # print(chars)\n","            train_input[index, word_count] = dict[\"input_corpus_dict\"][chars]\n","            index += 1\n","        word_count += 1\n","\n","    word_count = 0\n","    for words in ty:\n","        index = 0\n","        for chars in words:\n","            # print(chars)\n","            train_output[index, word_count] = dict[\"output_corpus_dict\"][chars]\n","            index += 1\n","        word_count += 1\n","\n","    word_count = 0\n","    for words in vx:\n","        index = 0\n","        for chars in words:\n","            # print(chars)\n","            val_input[index, word_count] = dict[\"input_corpus_dict\"][chars]\n","            index += 1\n","        word_count += 1\n","\n","    word_count = 0\n","    for words in vy:\n","        index = 0\n","        for chars in words:\n","            # print(chars)\n","            val_output[index, word_count] = dict[\"output_corpus_dict\"][chars]\n","            index += 1\n","        word_count += 1\n","\n","\n","    # Convert in tensor\n","    train_input = torch.tensor(train_input)\n","    train_output = torch.tensor(train_output)\n","    val_input = torch.tensor(val_input)\n","    val_output = torch.tensor(val_output)\n","\n","    return_dict = {\n","        \"train_input\" : train_input,\n","        \"train_output\" : train_output,\n","        \"val_input\" : val_input,\n","        \"val_output\" : val_output,\n","    }\n","    return return_dict"]},{"cell_type":"code","execution_count":43,"id":"04e96584","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:46.575139Z","iopub.status.busy":"2024-04-23T15:46:46.574827Z","iopub.status.idle":"2024-04-23T15:46:47.173507Z","shell.execute_reply":"2024-04-23T15:46:47.172518Z","shell.execute_reply.started":"2024-04-23T15:46:46.575112Z"},"papermill":{"duration":0.62814,"end_time":"2024-04-22T12:27:48.723514","exception":false,"start_time":"2024-04-22T12:27:48.095374","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'': 0, '#': 1, '$': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n","{'': 0, '#': 1, '$': 2, 'ँ': 3, 'ं': 4, 'ः': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ए': 13, 'ऐ': 14, 'ऑ': 15, 'ओ': 16, 'औ': 17, 'क': 18, 'ख': 19, 'ग': 20, 'घ': 21, 'ङ': 22, 'च': 23, 'छ': 24, 'ज': 25, 'झ': 26, 'ञ': 27, 'ट': 28, 'ठ': 29, 'ड': 30, 'ढ': 31, 'ण': 32, 'त': 33, 'थ': 34, 'द': 35, 'ध': 36, 'न': 37, 'प': 38, 'फ': 39, 'ब': 40, 'भ': 41, 'म': 42, 'य': 43, 'र': 44, 'ल': 45, 'ळ': 46, 'व': 47, 'श': 48, 'ष': 49, 'स': 50, 'ह': 51, '़': 52, 'ऽ': 53, 'ा': 54, 'ि': 55, 'ी': 56, 'ु': 57, 'ू': 58, 'ृ': 59, 'ॅ': 60, 'े': 61, 'ै': 62, 'ॉ': 63, 'ॊ': 64, 'ो': 65, 'ौ': 66, '्': 67}\n","torch.Size([27, 51200])\n","torch.Size([27, 51200])\n"]}],"source":["tensors = create_tensor(tx, ty, vx, vy, res, res_dict)\n","train_input = tensors[\"train_input\"]\n","val_input = tensors[\"val_input\"]\n","train_output = tensors[\"train_output\"]\n","val_output = tensors[\"val_output\"]\n","print(train_input.shape)\n","print(train_output.shape)"]},{"cell_type":"markdown","id":"e694a3e7","metadata":{"papermill":{"duration":0.009347,"end_time":"2024-04-22T12:27:48.744339","exception":false,"start_time":"2024-04-22T12:27:48.734992","status":"completed"},"tags":[]},"source":["## **Encoder, Decoder & Seq2Seq**"]},{"cell_type":"code","execution_count":44,"id":"09240c4c","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:47.175242Z","iopub.status.busy":"2024-04-23T15:46:47.174921Z","iopub.status.idle":"2024-04-23T15:46:47.202050Z","shell.execute_reply":"2024-04-23T15:46:47.201022Z","shell.execute_reply.started":"2024-04-23T15:46:47.175215Z"},"papermill":{"duration":0.031905,"end_time":"2024-04-22T12:27:48.785500","exception":false,"start_time":"2024-04-22T12:27:48.753595","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, PARAM):\n","        super(Encoder, self).__init__()\n","        self.input_size = PARAM[\"encoder_input_size\"]\n","        self.embedding_size = PARAM[\"encoder_embedding_size\"]\n","        self.hidden_size = PARAM[\"encoder_hidden_size\"]\n","        self.num_layers = PARAM[\"encoder_num_layers\"]\n","        self.drop_prob = PARAM[\"encoder_dropout_prob\"]\n","        self.cell_name = PARAM[\"encoder_cell_type\"]\n","        self.bidirectional = PARAM[\"bidirectional\"]\n","\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n","        if self.cell_name == \"LSTM\":\n","            self.cell = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.drop_prob, bidirectional = self.bidirectional)\n","        if self.cell_name == \"GRU\":\n","            self.cell = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.drop_prob, bidirectional = self.bidirectional)\n","        if self.cell_name == \"RNN\":\n","            self.cell = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.drop_prob, bidirectional = self.bidirectional)\n","    \n","    def forward(self, x):\n","        embedding = self.embedding(x)\n","        drops = self.dropout(embedding)\n","        if self.cell_name == \"RNN\" or self.cell_name == \"GRU\":\n","            cells = None\n","            outputs, hidden = self.cell(drops)\n","        elif self.cell_name == \"LSTM\":\n","            outputs, (hidden, cells)= self.cell(drops)\n","        return hidden, cells\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, PARAM):\n","        super(Decoder, self).__init__()\n","        self.input_size = PARAM[\"decoder_input_size\"]\n","        self.embedding_size = PARAM[\"decoder_embedding_size\"]\n","        self.hidden_size = PARAM[\"decoder_hidden_size\"]\n","        self.output_size = PARAM[\"decoder_output_size\"]\n","        self.num_layers = PARAM[\"decoder_num_layers\"]\n","        self.drop_prob = PARAM[\"decoder_dropout_prob\"]\n","        self.cell_name = PARAM[\"decoder_cell_type\"]\n","        self.bidirectional = PARAM[\"bidirectional\"]\n","        self.dropout = nn.Dropout(self.drop_prob)\n","        self.embedding = nn.Embedding(self.input_size, self.embedding_size)\n","        \n","        if self.cell_name == \"LSTM\":\n","            self.cell = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.drop_prob, bidirectional = self.bidirectional)\n","        if self.cell_name == \"GRU\":\n","            self.cell = nn.GRU(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.drop_prob, bidirectional = self.bidirectional)\n","        if self.cell_name == \"RNN\":\n","            self.cell = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers, dropout = self.drop_prob, bidirectional = self.bidirectional)\n","            \n","        if self.bidirectional:\n","            self.fc = nn.Linear(self.hidden_size*2, self.output_size)\n","        else:\n","            self.fc = nn.Linear(self.hidden_size, self.output_size)\n","    \n","    def forward(self, x, hidden, cells):\n","        x = x.unsqueeze(0)\n","        embedding = self.embedding(x)\n","        drops = self.dropout(embedding)\n","        if self.cell_name == \"RNN\" or self.cell_name == \"GRU\":\n","            outputs, hidden = self.cell(drops, hidden)\n","        elif self.cell_name == \"LSTM\":\n","            outputs, (hidden, cells) = self.cell(drops, (hidden, cells))\n","        predictions = self.fc(outputs).squeeze(0)\n","        predictions = F.log_softmax(predictions, dim = 1)\n","        return predictions, hidden, cells\n","    \n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, param):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.teacher_forcing_ratio = param[\"tfr\"]\n","    \n","    def forward(self, src, target):\n","        batch_size = src.shape[1]\n","        target_len = target.shape[0]\n","        \n","        target_vocab_size = len(output_corpus_dict)\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n","\n","        encoder_hidden, cell = self.encoder(src)\n","\n","        x = target[0]\n","        \n","        for tar in range(1, target_len):\n","            output, encoder_hidden, cell = self.decoder(x, encoder_hidden, cell)\n","            outputs[tar] = output\n","\n","            if random.random() < self.teacher_forcing_ratio:\n","                x = target[tar]\n","            else:\n","                x = output.argmax(dim=1)\n","        \n","        return outputs"]},{"cell_type":"code","execution_count":45,"id":"1c26364d","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:47.203826Z","iopub.status.busy":"2024-04-23T15:46:47.203406Z","iopub.status.idle":"2024-04-23T15:46:47.216174Z","shell.execute_reply":"2024-04-23T15:46:47.215382Z","shell.execute_reply.started":"2024-04-23T15:46:47.203790Z"},"papermill":{"duration":0.017944,"end_time":"2024-04-22T12:27:48.939391","exception":false,"start_time":"2024-04-22T12:27:48.921447","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# def predict(model, PARAM):\n","#     \"\"\"\n","#     Predict the output sequence given an input word using the trained model.\n","\n","#     Args:\n","#         model (nn.Module): The trained model.\n","#         PARAM (dict): Dictionary containing necessary parameters including:\n","#             - \"word\" (str): Input word to be translated.\n","#             - \"input_corpus_dict\" (dict): Dictionary mapping input characters to indices.\n","#             - \"output_corpus_dict\" (dict): Dictionary mapping output indices to characters.\n","#             - \"reversed_output_corpus\" (dict): Dictionary mapping output characters to indices.\n","\n","#     Returns:\n","#         str: Predicted output sequence.\n","#     \"\"\"\n","#     word = PARAM[\"word\"]\n","#     input_char_index = PARAM[\"input_corpus_dict\"]\n","#     output_char_index = PARAM[\"output_corpus_dict\"]\n","#     reverse_target_char_index = PARAM[\"reversed_output_corpus\"]\n","    \n","#     data = np.zeros((len(input_char_index), 1), dtype=int)\n","#     word_t = ''\n","#     t_z = 0\n","    \n","#     for t, char in enumerate(word):\n","#         data[t, 0] = input_char_index.get(char, input_char_index['$'])\n","#     t_z = t + 1   \n","#     data[t_z:, 0] = input_char_index['$']\n","    \n","#     data = torch.tensor(data, dtype=torch.int64).to(device)\n","\n","#     with torch.no_grad():\n","#         hidden, cell = model.encoder(data)\n","    \n","#     output_char = output_char_index['#']    \n","#     out_chr_reshape = np.array(output_char).reshape(1,)    \n","#     x = torch.tensor(out_chr_reshape).to(device)\n","\n","#     for _ in range(1, len(output_char_index)):\n","#         output, hidden, cell = model.decoder(x, hidden, cell)\n","#         predicted_index = output.argmax(1).item()\n","#         predicted_char = reverse_target_char_index.get(predicted_index, '$')\n","        \n","#         if predicted_char != '$':\n","#             word_t += predicted_char\n","#         else:\n","#             break\n","\n","#     return word_t\n","\n","# # Define the input sequence\n","# # PARAM_PRED = {\n","# #     \"word\" : \"aditya\",\n","# #     \"input_corpus_dict\" : input_corpus_dict,\n","# #     \"output_corpus_dict\" : output_corpus_dict,\n","# #     \"reversed_output_corpus\" : reversed_output_corpus,\n","# # }\n","\n","# # lst = [\"harsh\", \"ayush\", \"aditya\", \"raghav\", \"antim\", \"tanish\", \"priyakant\"]\n","# # for word in lst:\n","# #     PARAM_PRED['word'] = word\n","# #     output_sequence = predict(model, PARAM_PRED)\n","# #     print(PARAM_PRED[\"word\"], end = \" ==> \")\n","# #     print(output_sequence)"]},{"cell_type":"markdown","id":"37837ceb","metadata":{},"source":["## **Setting Optimizer**"]},{"cell_type":"code","execution_count":46,"id":"601ac203","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:47.220945Z","iopub.status.busy":"2024-04-23T15:46:47.220586Z","iopub.status.idle":"2024-04-23T15:46:47.230911Z","shell.execute_reply":"2024-04-23T15:46:47.230022Z","shell.execute_reply.started":"2024-04-23T15:46:47.220919Z"},"trusted":true},"outputs":[],"source":["def set_optimizer(name, model, learning_rate):\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    if name == \"adam\":\n","        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    if name == \"sgd\":\n","        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n","    if name == \"rmsprop\":\n","        optimizer = optim.RMSprop(model.parameters(), lr = learning_rate)\n","    if name == \"adagrad\":\n","        optimizer = optim.Adagrad(model.parameters(), lr = learning_rate)\n","    return optimizer"]},{"cell_type":"markdown","id":"9c10b970","metadata":{"papermill":{"duration":0.008958,"end_time":"2024-04-22T12:27:48.957549","exception":false,"start_time":"2024-04-22T12:27:48.948591","status":"completed"},"tags":[]},"source":["## **BEAM SEARCH**"]},{"cell_type":"code","execution_count":47,"id":"f1a4af60","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:47.232171Z","iopub.status.busy":"2024-04-23T15:46:47.231930Z","iopub.status.idle":"2024-04-23T15:46:47.246946Z","shell.execute_reply":"2024-04-23T15:46:47.245973Z","shell.execute_reply.started":"2024-04-23T15:46:47.232150Z"},"papermill":{"duration":0.027161,"end_time":"2024-04-22T12:27:48.994201","exception":false,"start_time":"2024-04-22T12:27:48.967040","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def beam_search(PARAM, model, word, device, max_encoder_length, input_corpus_dict, output_corpus_dict, reverse_output_corpus):\n","    dtype = torch.int32\n","    data, word_t = np.zeros((max_encoder_length, 1), dtype=np.int32), \"\"\n","    index = 0\n","    for character in word:\n","        data[index, 0] = input_corpus_dict[character]\n","        index += 1\n","    data[index, 0] = input_corpus_dict['$']\n","    \n","    data = torch.tensor(data, dtype=torch.int32).to(device)\n","\n","    with torch.no_grad():\n","        hidden, cell = model.encoder(data)\n","    \n","    output_start = output_corpus_dict['#']\n","    out_reshape = np.array(output_start).reshape(1,)\n","    hidden_par = hidden.unsqueeze(0)\n","    initial_sequence = torch.tensor(out_reshape).to(device)\n","    beam = [(0.0, initial_sequence, hidden_par)]\n","\n","    for i in range(len(output_corpus_dict)):\n","        candidates = []\n","        for score, seq, hidden in beam:\n","            if seq[-1].item() == output_corpus_dict['$']:\n","                candidates.append((score, seq, hidden))\n","                continue\n","            \n","            reshape_last = np.array(seq[-1].item()).reshape(1, )\n","            hdn = hidden.squeeze(0) \n","            x = torch.tensor(reshape_last).to(device)\n","            output, hidden, cell = model.decoder(x, hdn, cell)\n","            probabilities = F.softmax(output, dim=1)\n","            topk_probs, topk_tokens = torch.topk(probabilities, k = PARAM[\"beam_width\"])               \n","        \n","            for prob, token in zip(topk_probs[0], topk_tokens[0]):\n","                new_seq = torch.cat((seq, token.unsqueeze(0)), dim=0)\n","                ln_ns = len(new_seq)\n","                ln_pf = ((ln_ns - 1) / 5)\n","                candidate_score = score + torch.log(prob).item() / (ln_pf ** PARAM[\"length_panelty\"])\n","                candidates.append((candidate_score, new_seq, hidden.unsqueeze(0)))\n","        \n","        beam = heapq.nlargest(PARAM[\"beam_width\"], candidates, key=lambda x: x[0])\n","    \n","    best_score, best_sequence, _ = max(beam, key=lambda x: x[0]) \n","    \n","    word_t = ''.join([reverse_output_corpus[token.item()] for token in best_sequence[1:]])\n","    \n","    return word_t[:-1]\n","            \n","  "]},{"cell_type":"code","execution_count":48,"id":"10f5feea","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:47.248559Z","iopub.status.busy":"2024-04-23T15:46:47.248251Z","iopub.status.idle":"2024-04-23T15:46:47.266180Z","shell.execute_reply":"2024-04-23T15:46:47.265096Z","shell.execute_reply.started":"2024-04-23T15:46:47.248534Z"},"trusted":true},"outputs":[],"source":["def run_epoch(model, train_batches_x, train_batches_y, optimizer, loss_function):\n","    total_words = 0\n","    correct_pred = 0\n","    total_loss = 0\n","    model.train()\n","\n","    with tqdm(total=len(train_batches_x), desc='Training') as pbar:\n","        for i, ( x_batch, y_batch) in enumerate(zip(train_batches_x, train_batches_y)):\n","            target_batch, input_batch = y_batch.to(device), x_batch.to(device)\n","            optimizer.zero_grad()\n","            output_batch = model(input_batch, target_batch)\n","            mask = (target_batch != output_corpus_dict[''])  # Padding mask\n","            non_pad_targets = target_batch[mask]\n","            non_pad_outputs = output_batch[mask].reshape(-1, output_batch.shape[2])\n","            loss = loss_function(non_pad_outputs, non_pad_targets)\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","            optimizer.step()\n","            total_words += non_pad_targets.size(0)\n","            correct_pred += torch.sum(torch.argmax(non_pad_outputs, dim=1) == non_pad_targets).item()\n","            total_loss += loss.item()\n","            pbar.update(1)\n","    accuracy = correct_pred / total_words\n","    avg_loss = total_loss / len(train_batches_x)  # Average loss per batch\n","    \n","    return accuracy, avg_loss\n","\n","def evaluate_using_char(model, val_batches_x, val_batches_y, loss_function):\n","    model.eval()\n","    with torch.no_grad():\n","        val_total_loss = 0\n","        val_total_words = 0\n","        val_correct_pred = 0\n","\n","        with tqdm(total=len(val_batches_x), desc='Validation') as pbar:\n","            for i, (x_val_batch, y_val_batch) in enumerate(zip(val_batches_x, val_batches_y)):\n","                target_val_batch, input_val_batch = y_val_batch.to(device), x_val_batch.to(device)\n","                output_val_batch = model(input_val_batch, target_val_batch)\n","                mask = (target_val_batch != output_corpus_dict[''])  # Padding mask\n","                non_pad_targets_val = target_val_batch[mask]\n","                non_pad_outputs_val = output_val_batch[mask].reshape(-1, output_val_batch.shape[2])\n","                val_loss = loss_function(non_pad_outputs_val, non_pad_targets_val)\n","                val_total_loss += val_loss.item()\n","                val_total_words += non_pad_targets_val.size(0)\n","                val_correct_pred += torch.sum(torch.argmax(non_pad_outputs_val, dim=1) == non_pad_targets_val).item()\n","                pbar.update(1)\n","\n","    val_accuracy = val_correct_pred / val_total_words\n","    val_avg_loss = val_total_loss / len(val_batches_x)\n","        \n","    return val_accuracy, val_avg_loss\n","\n","def evaluate_using_words(PARAM, model, val_input, vx, vy):\n","    model.eval()\n","    with torch.no_grad():\n","        val_total_words_beam = 0\n","        val_correct_pred_beam = 0\n","        with tqdm(total=val_input.shape[1], desc='Validation_With_Beam_Search') as pbar:\n","            for word, target_word in zip(vx, vy):\n","                val_total_words_beam += 1\n","                predicted_word = beam_search(PARAM, model, word, device, max_encoder_length, input_corpus_dict, output_corpus_dict, reversed_output_corpus)\n","                if predicted_word == target_word[1:-1]:\n","                    val_correct_pred_beam += 1\n","                pbar.update(1)\n","\n","    val_accuracy_beam = val_correct_pred_beam / val_total_words_beam\n","        \n","    return val_accuracy_beam, val_correct_pred_beam\n","    \n","    \n","\n"]},{"cell_type":"markdown","id":"232fccc3","metadata":{"papermill":{"duration":0.009195,"end_time":"2024-04-22T12:27:49.012983","exception":false,"start_time":"2024-04-22T12:27:49.003788","status":"completed"},"tags":[]},"source":["## **Train Using Beam Search**"]},{"cell_type":"code","execution_count":49,"id":"03cc6dc3","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:46:47.267856Z","iopub.status.busy":"2024-04-23T15:46:47.267512Z","iopub.status.idle":"2024-04-23T15:46:47.283129Z","shell.execute_reply":"2024-04-23T15:46:47.282319Z","shell.execute_reply.started":"2024-04-23T15:46:47.267828Z"},"papermill":{"duration":0.009035,"end_time":"2024-04-22T12:27:49.031338","exception":false,"start_time":"2024-04-22T12:27:49.022303","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["HYPER_PARAM = {\n","    \"encoder_input_size\": len(input_corpus_dict),\n","    \"encoder_embedding_size\": 256,\n","    \"encoder_hidden_size\": 512,\n","    \"encoder_num_layers\": 3,\n","    \"encoder_dropout_prob\": 0.1,\n","    \"encoder_cell_type\": \"LSTM\",\n","    \"decoder_input_size\": len(output_corpus_dict),\n","    \"decoder_embedding_size\": 256,\n","    \"decoder_hidden_size\": 512,\n","    \"decoder_output_size\": len(output_corpus_dict),\n","    \"decoder_num_layers\": 3,\n","    \"decoder_dropout_prob\": 0.1,\n","    \"decoder_cell_type\": \"LSTM\",\n","    \"beam_width\" : 1,\n","    \"length_panelty\" : 0.6,\n","    \"bidirectional\" : True,\n","    \"learning_rate\" : 0.001,\n","    \"batch_size\" : 64,\n","    \"epochs\" : 1,\n","    \"optimizer\" : \"adam\",\n","    \"tfr\" : 0.5,\n","}\n","\n","def training(PARAM, wandb_log = 0):\n","    if wandb_log == 1:\n","        wandb.init(project='DL-Assignment3')\n","        wandb.run.name = 'Testing'\n","    learning_rate = PARAM[\"learning_rate\"]\n","    epochs = PARAM[\"epochs\"]\n","    batch_size = PARAM[\"batch_size\"]\n","\n","    encoder = Encoder(PARAM).to(device)\n","    decoder = Decoder(PARAM).to(device)\n","\n","#     # Initialize model\n","    model = Seq2Seq(encoder, decoder, PARAM).to(device)\n","    print(model)\n","\n","    # Define loss function and optimizer\n","    loss_function = nn.CrossEntropyLoss()\n","    optimizer = set_optimizer(PARAM[\"optimizer\"], model, learning_rate)\n","\n","    # Split dataset into batches\n","    train_batches_x = torch.split(train_input, batch_size, dim=1)\n","    train_batches_y = torch.split(train_output, batch_size, dim=1)\n","    val_batches_x = torch.split(val_input, batch_size, dim=1)\n","    val_batches_y = torch.split(val_output, batch_size, dim=1)\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        print(f\"Epoch :: {epoch+1}/{epochs}\")\n","        \n","        accuracy, avg_loss = run_epoch(model, train_batches_x, train_batches_y, optimizer, loss_function)  # Average loss per batch\n","\n","        val_accuracy, val_avg_loss = evaluate_using_char(model, val_batches_x, val_batches_y, loss_function)\n","\n","        val_accuracy_beam, val_correct_pred_beam = evaluate_using_words(PARAM, model, val_input, vx, vy)\n","        print(f\"Epoch : {epoch+1} Train Accuracy: {accuracy*100:.4f}, Train Loss: {avg_loss:.4f}\\nValidation Accuracy: {val_accuracy*100:.4f}, Validation Loss: {val_avg_loss:.4f}, \\nValidation Acc. With BeamSearch: {val_accuracy_beam*100:.4f}, Correctly Predicted : {val_correct_pred_beam}/{val_input.shape[1]}\")\n","        if wandb_log:\n","            wandb.log(\n","                    {\n","                        'epoch': epoch+1,\n","                        'training_loss' : avg_loss,\n","                        'training_accuracy' : accuracy,\n","                        'validation_loss' : val_avg_loss,\n","                        'validation_accuracy_using_char' : val_accuracy,\n","                        'validation_accuracy_using_word' : val_accuracy_beam,\n","                        'correctly_predicted' : val_correct_pred_beam\n","                    }\n","                )\n","    if wandb_log == 1:\n","        wandb.finish()\n","    return model, val_accuracy_beam"]},{"cell_type":"code","execution_count":51,"id":"c7a6246d","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:47:22.362121Z","iopub.status.busy":"2024-04-23T15:47:22.361722Z","iopub.status.idle":"2024-04-23T15:49:52.910959Z","shell.execute_reply":"2024-04-23T15:49:52.909985Z","shell.execute_reply.started":"2024-04-23T15:47:22.362089Z"},"papermill":{"duration":0.017322,"end_time":"2024-04-22T12:27:49.170183","exception":false,"start_time":"2024-04-22T12:27:49.152861","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (embedding): Embedding(29, 256)\n","    (cell): LSTM(256, 512, num_layers=3, dropout=0.1, bidirectional=True)\n","  )\n","  (decoder): Decoder(\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (embedding): Embedding(68, 256)\n","    (cell): LSTM(256, 512, num_layers=3, dropout=0.1, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=68, bias=True)\n","  )\n",")\n","Epoch :: 0/1\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 800/800 [01:40<00:00,  7.97it/s]\n","Validation: 100%|██████████| 64/64 [00:02<00:00, 24.81it/s]\n","Validation_With_Beam_Search: 100%|██████████| 4096/4096 [00:47<00:00, 86.76it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch : 1 Train Accuracy: 55.7133, Train Loss: 1.5694\n","Validation Accuracy: 67.4065, Validation Loss: 1.1684, \n","Validation Acc. With BeamSearch: 27.4414, Correctly Predicted : 1124/4096\n","<class 'list'>\n","ज़ई श्रे कृष्णा "]}],"source":["model, acc = training(HYPER_PARAM, wandb_log = 0)\n","\n","sentance = \"Jai shree krishna\"\n","sentance = sentance.lower()\n","lst = sentance.split(\" \")\n","print(type(lst))\n","for word in lst:\n","    output_sequence = beam_search(HYPER_PARAM, model, word ,device, max_encoder_length, input_corpus_dict, output_corpus_dict, reversed_output_corpus)\n","    print(output_sequence, end = \" \")"]},{"cell_type":"code","execution_count":52,"id":"1fdd3ce4","metadata":{"execution":{"iopub.execute_input":"2024-04-23T15:50:19.583726Z","iopub.status.busy":"2024-04-23T15:50:19.583339Z","iopub.status.idle":"2024-04-23T15:50:19.723720Z","shell.execute_reply":"2024-04-23T15:50:19.722533Z","shell.execute_reply.started":"2024-04-23T15:50:19.583694Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","परित्रणायय सधुऊनम विनाशायय चादुष्कृततम धर्मा समस्थापाराथ्या संभावामी युगे युगे एएए "]}],"source":["sentance = \"paritraanaaya sadhuunaam vinaashaaya chadushkritaam dharma samsthaapanaarthaaya sambhavaami yuge yuge\"\n","sentance = sentance.lower()\n","lst = sentance.split(\" \")\n","print(type(lst))\n","for word in lst:\n","    output_sequence = beam_search(HYPER_PARAM, model, word ,device, max_encoder_length, input_corpus_dict, output_corpus_dict, reversed_output_corpus)\n","    print(output_sequence, end = \" \")"]},{"cell_type":"markdown","id":"9761b5ca","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"id":"a82c9c98","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:47:20.402937Z","iopub.status.idle":"2024-04-23T15:47:20.403285Z","shell.execute_reply":"2024-04-23T15:47:20.403136Z","shell.execute_reply.started":"2024-04-23T15:47:20.403121Z"},"papermill":{"duration":0.020451,"end_time":"2024-04-22T12:27:49.200094","exception":false,"start_time":"2024-04-22T12:27:49.179643","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sweep_config = {\n","            'name': 'sweep random 1',\n","            'method': 'random',\n","            'metric': { 'goal': 'maximize','name': 'Accuracy'},\n","            'parameters': \n","                {\n","                    'epochs': {'values': [10]},\n","                    'cell_type': {'values': ['RNN', 'LSTM', 'GRU']},\n","                    'embedding_size': {'values': [128, 256, 512]},\n","                    'hidden_size': {'values': [128, 256, 512, 1024]},\n","                    'num_layers': {'values': [1, 2, 3]},\n","                    'dropout': {'values': [0.3, 0.5, 0.7]},\n","                    'optimizer' : {'values' : ['adam', 'sgd', 'rmsprop', 'adagrad']},\n","                    'learning_rate': {'values': [0.001, 0.005, 0.01, 0.1]},\n","                    'batch_size': {'values': [32, 64]},\n","                    'teacher_fr' : {'values': [0.3, 0.5, 0.7]},\n","                    'length_penalty' : {'values': [0.4, 0.5, 0.6]},\n","                    'bi_dir' : {'values': [True, False]},\n","                    'beam_width': {'values': [1, 2, 3]}\n","                }\n","            }"]},{"cell_type":"code","execution_count":null,"id":"143bedab","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:47:20.404418Z","iopub.status.idle":"2024-04-23T15:47:20.404726Z","shell.execute_reply":"2024-04-23T15:47:20.404581Z","shell.execute_reply.started":"2024-04-23T15:47:20.404568Z"},"papermill":{"duration":0.021012,"end_time":"2024-04-22T12:27:49.230944","exception":false,"start_time":"2024-04-22T12:27:49.209932","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def train():\n","    var1 = wandb.init(project=\"DL-Assignment3\")\n","    var2 = var1.config\n","   \n","    wandb.run.name = (f\"cell_type:{var2.cell_type}_epochs:{var2.epochs}_lr:{var2.learning_rate}_batch_size:{var2.batch_size}_beam_width:{var2.beam_width}_opt:{var2.optimizer}_dropout:{var2.dropout}_teacher_fr:{var2.teacher_fr}_embadding_size:{var2.embedding_size}\")\n","\n","    HYPER_PARAM = {\n","    \"encoder_input_size\": len(input_corpus_dict),\n","    \"encoder_embedding_size\": var2.embedding_size,\n","    \"encoder_hidden_size\": var2.hidden_size,\n","    \"encoder_num_layers\": var2.num_layers,\n","    \"encoder_dropout_prob\": var2.dropout,\n","    \"encoder_cell_type\": var2.cell_type,\n","    \"decoder_input_size\": len(output_corpus_dict),\n","    \"decoder_embedding_size\": var2.embedding_size,\n","    \"decoder_hidden_size\": var2.hidden_size,\n","    \"decoder_output_size\": len(output_corpus_dict),\n","    \"decoder_num_layers\": var2.num_layers,\n","    \"decoder_dropout_prob\": var2.dropout,\n","    \"decoder_cell_type\": var2.cell_type,\n","    \"beam_width\" : var2.beam_width,\n","    \"length_panelty\" : var2.length_penalty,\n","    \"bidirectional\" : var2.bi_dir,\n","    \"learning_rate\" : var2.learning_rate,\n","    \"batch_size\" : var2.batch_size,\n","    \"epochs\" : var2.epochs,\n","    \"optimizer\" : var2.optimizer,\n","    \"tfr\" : var2.teacher_fr,\n","}\n","\n","    model, accuracy = training(HYPER_PARAM, wandb_log = 1)\n","    wandb.log({\n","                \"Accuracy\" : accuracy\n","            })"]},{"cell_type":"code","execution_count":null,"id":"274cce09","metadata":{"execution":{"iopub.status.busy":"2024-04-23T15:47:20.406247Z","iopub.status.idle":"2024-04-23T15:47:20.406557Z","shell.execute_reply":"2024-04-23T15:47:20.406419Z","shell.execute_reply.started":"2024-04-23T15:47:20.406406Z"},"papermill":{"duration":10628.113884,"end_time":"2024-04-22T15:24:57.354431","exception":false,"start_time":"2024-04-22T12:27:49.240547","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["sweep_id = wandb.sweep(sweep_config, project=\"DL-Assignment3\")\n","wandb.agent(sweep_id, train)\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"papermill":{"duration":7.61018,"end_time":"2024-04-22T15:25:12.330452","exception":false,"start_time":"2024-04-22T15:25:04.720272","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4830707,"sourceId":8164175,"sourceType":"datasetVersion"},{"datasetId":4844106,"sourceId":8181791,"sourceType":"datasetVersion"},{"datasetId":4861591,"sourceId":8205199,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":10667.002796,"end_time":"2024-04-22T15:25:23.121216","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-22T12:27:36.118420","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}
